<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on B🐶Pythonic</title>
    <link>http://danigong.github.io/post/</link>
    <description>Recent content in Posts on B🐶Pythonic</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Wed, 07 Mar 2018 17:09:40 +0800</lastBuildDate>
    <atom:link href="http://danigong.github.io/post/feed/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>How to create a github.io repo</title>
      <link>http://danigong.github.io/post/how_to_create_a_github_io_repo/</link>
      <pubDate>Wed, 07 Mar 2018 17:09:40 +0800</pubDate>
      
      <guid>http://danigong.github.io/post/how_to_create_a_github_io_repo/</guid>
      <description>

&lt;h2 id=&#34;开通自己的github-io-repo:018a1d9a116761721e09a6de2cf767a8&#34;&gt;开通自己的github.io repo&lt;/h2&gt;

&lt;p&gt;github.io是完全基于github创建的，其本质上是在你的github账户下创建一个特殊的repo。你可以参照如下步骤完成：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;创建repo&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;当然，一切的前提是你得首先有个github的账户，这里还请自行解决。登陆你的账户后，你可以创建一个新的repo。请务必注意该repo的名字，必须保持格式&lt;code&gt;&amp;lt;username&amp;gt;.github.io&lt;/code&gt;，其中&lt;code&gt;&amp;lt;username&amp;gt;&lt;/code&gt;替换成你的github账户名，这里假定创建的repo为&lt;code&gt;danielgong.github.io&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;把你创建的repo clone到本地就可以了&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;git clone https://github.com/tobiasalin/tobiasalin.github.io&lt;/code&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to update hugo blog</title>
      <link>http://danigong.github.io/post/how_to_update_hugo_blog/</link>
      <pubDate>Wed, 07 Mar 2018 16:45:07 +0800</pubDate>
      
      <guid>http://danigong.github.io/post/how_to_update_hugo_blog/</guid>
      <description>

&lt;h3 id=&#34;quick-start:a9f50bd812f223c6d6f384347fb30a71&#34;&gt;Quick Start&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;1. Open iTerm2&lt;/li&gt;
&lt;li&gt;2. &lt;code&gt;control+command+h&lt;/code&gt; to open the tab with hugo profile&lt;/li&gt;
&lt;li&gt;3. &lt;code&gt;addblog&lt;/code&gt; to create a new blog post, hugo command will create a new post tesmplate and subl command will help open it.&lt;/li&gt;
&lt;li&gt;4. &lt;code&gt;deployblog&lt;/code&gt; to deploy newest update to github.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;detail:a9f50bd812f223c6d6f384347fb30a71&#34;&gt;Detail&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;create blog shell script:&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;echo &amp;quot;Blog Title: &amp;quot;
read Title
cd /Users/DanielGong/HugoSite/testsite
hugo new post/$Title.md
subl /Users/DanielGong/HugoSite/testsite/content/post/$Title.md
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;deploy blog shell script:&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;echo &amp;quot;-------Begin-------&amp;quot;

cd /Users/DanielGong/HugoSite/testsite
hugo --theme=gs-hyde --baseUrl=&amp;quot;http://danigong.github.io/&amp;quot;
cd public
git add -A
git commit -m &amp;quot;auto_commit&amp;quot;
git push origin master

echo &amp;quot;-------Done-------&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;customize command:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Add &lt;code&gt;alias addblog=&amp;quot;xxx.sh&amp;quot;&lt;/code&gt; into &lt;code&gt;.bashrc&lt;/code&gt; file. Then &lt;code&gt;source ~/.bashrc&lt;/code&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Markdown Online Editor</title>
      <link>http://danigong.github.io/post/markdown_online_editor/</link>
      <pubDate>Wed, 07 Mar 2018 11:25:30 +0800</pubDate>
      
      <guid>http://danigong.github.io/post/markdown_online_editor/</guid>
      <description>

&lt;h2 id=&#34;online-markdown-language-editor:c499e7739e346a86c3c869288ba7a676&#34;&gt;Online Markdown Language Editor&lt;/h2&gt;

&lt;p&gt;Visit: &lt;a href=&#34;https://www.zybuluo.com/mdeditor&#34;&gt;https://www.zybuluo.com/mdeditor&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The best django project structure</title>
      <link>http://danigong.github.io/post/The-best-django-project-structure/</link>
      <pubDate>Mon, 05 Mar 2018 11:01:39 +0800</pubDate>
      
      <guid>http://danigong.github.io/post/The-best-django-project-structure/</guid>
      <description>

&lt;h1 id=&#34;项目目录结构:dfe114c833a99a64f54e2cfb47175ca9&#34;&gt;项目目录结构&lt;/h1&gt;

&lt;p&gt;在上一节里我们使用Django的django-admin startproject命令来创建了一个Helloworld的项目，在没有写任何代码的情况下成功运行了这个项目。虽然目前来说这个项目没有任何功能，但是这是我们一个成功的开始，不是吗？&lt;/p&gt;

&lt;h3 id=&#34;helloworld项目的目录结构:dfe114c833a99a64f54e2cfb47175ca9&#34;&gt;Helloworld项目的目录结构&lt;/h3&gt;

&lt;p&gt;我们来看一下这个项目的目录结构&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://zhiwehu.gitbooks.io/build-web-application-with-python-django/content/assets/Helloworld project directory structure.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;最外层的Helloworld目录，是项目的根目录，在这个目录下我们看到有2个文件，一个是&lt;code&gt;db.sqlite3&lt;/code&gt;是数据库文件，另一个是&lt;code&gt;manage.py&lt;/code&gt;是Django提供的一个管理工具入口，比如上一节中我们使用python manage.py runserver来运行这个web app。
根目录下面的Helloworld目录，是项目的配置目录，里面放了Django的一些配置信息，包括一个&lt;code&gt;settings.py&lt;/code&gt;，一个根&lt;code&gt;urls.py&lt;/code&gt;和&lt;code&gt;wsgi.py&lt;/code&gt;，这些都是Django运行所需要的配置性文件。
还有一个firstapp是我使用&lt;code&gt;django-admin startapp firstapp&lt;/code&gt;这个命令创建的一个app，这相当是这个项目的一个功能性的app，Django使用app来划分模块。
这个项目目录结构好吗？
虽然我们使用了Django提供的django-admin创建的项目目录结构看起来很简单明了，但是我们应该知道，这只是供学习使用的，在真正的项目里，估计就没有人这样使用了。一个真实的产品项目，我们需要有更多的配置信息、文档、测试等，以及代码仓库配置等。而这个简单的目录结构显然是达不到这样的要求的。&lt;/p&gt;

&lt;h3 id=&#34;推荐的项目目录结构:dfe114c833a99a64f54e2cfb47175ca9&#34;&gt;推荐的项目目录结构&lt;/h3&gt;

&lt;p&gt;在本节里我重点是要介绍一个我认为是最佳的Django项目目录结构，当然所谓的『最佳』因人而异，我同时也会提供其他的一些选项供参考。接下来看一下这个&lt;strong&gt;目录结构&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://zhiwehu.gitbooks.io/build-web-application-with-python-django/content/assets/The best django project directory structure.png&#34; alt=&#34;tool-manager&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;接下来我详细说明一下这个目录结构:dfe114c833a99a64f54e2cfb47175ca9&#34;&gt;接下来我详细说明一下这个目录结构&lt;/h3&gt;

&lt;p&gt;最外层的project是项目根目录，这个目录除了之前的manage.py这个文件外，还有更多的配置文件，和其他子目录。这些配置文件后面会详细介绍。
config目录是配置目录，里面除了包含了根&lt;code&gt;urls.py&lt;/code&gt;文件和&lt;code&gt;wsgi.py&lt;/code&gt;文件，我们将原来的&lt;code&gt;settings.py&lt;/code&gt;扩展成为了一个Python package，因为我们在不同的环境中将使用不同的配置文件，在本地电脑上使用&lt;code&gt;settings.local.py&lt;/code&gt;，而在生产环境中使用&lt;code&gt;settings.production.py&lt;/code&gt;。
docs是文档目录
project目录是项目的apps目录，我们将这个web的apps都放在这个目录下面，比如这里已经有一个users的app，同时我们也看到有static和templates这2个目录，这2个并不是app，而是其他apps需要使用的静态文件目录和模板目录。
requirements目录是放置依赖包的索引文件，我们知道Python使用pip安装Python软件包，所以需要些些Python软件包我们就在一个txt文件里列出这些软件包的名字和版本号。注意我们同样是根据不同的环境有不同的软件包索引，开发环境和生产环境所依赖的Python软件包是不一样的，所以我们也分开在不同的文件中索引。
utility目录放的是一些项目的工具shell，比如运行这个项目操作系统需要安装的一些底层库和软件包等，这些一般是在部署时使用。
怎么创建这个目录结构？
每次开始一个新的Django项目，我们就需要初始化这个项目，创建这个项目的目录结构，然后进行开发。我们知道使用django-admin命令行工具是可以做到这一点的，我们用它来创建了Helloworld项目。而上面这个项目目录结构是怎么创建的呢？接下来我将介绍另一个非常实用的工具&lt;code&gt;cookiecutter&lt;/code&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>cookiecutter for django</title>
      <link>http://danigong.github.io/post/cookiecutter-for-django/</link>
      <pubDate>Mon, 05 Mar 2018 10:59:16 +0800</pubDate>
      
      <guid>http://danigong.github.io/post/cookiecutter-for-django/</guid>
      <description>&lt;p&gt;cookiecutter
这是一个专门用于创建项目目录结构的工具，同时也是使用Python来实现的，它可以使用一个模板来创建一个项目，比如上面我介绍的项目目录结构实际上是一个模板，也是github开源的，链接：&lt;a href=&#34;https://github.com/pydanny/cookiecutter-django&#34;&gt;https://github.com/pydanny/cookiecutter-django&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;安装cookiecutter
    &lt;code&gt;pip install cookiecutter&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;创建项目
    &lt;code&gt;cookiecutter https://github.com/pydanny/cookiecutter-django&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;运行上面第二个命令的时候，会问你一大堆问题，这些问题中下示例（附简短讲解）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Cloning into &#39;cookiecutter-django&#39;...
remote: Counting objects: 550, done.
remote: Compressing objects: 100% (310/310), done.
remote: Total 550 (delta 283), reused 479 (delta 222)
Receiving objects: 100% (550/550), 127.66 KiB | 58 KiB/s, done.
Resolving deltas: 100% (283/283), done.
# 问你项目叫什么名字，这里可以大小写，带空格
project_name [Project Name]: Reddit Clone
# 问你项目的根目录名字，一般是小写没有空格，这个会生成一个目录
project_slug [reddit_clone]: reddit
# 开发者名字
author_name [Daniel Roy Greenfeld]: Jeffrey Hu
# 开发者邮件
email [you@example.com]: zhiwehu@gmail.com
# 项目简短介绍
description [A short description of the project.]: A reddit clone.
# 项目域名
domain_name [example.com]: lettoo.com
# 项目版本号
version [0.1.0]: 0.0.1
# 时区，就选默认的UTC
timezone [UTC]: 
# 是否使用whitenoise，whitenoise是一个Python实现的静态文件host解决方案，建议初学者选No
use_whitenoise [y]: n
# 是否使用celery，[celery](http://www.celeryproject.org/)是一个Python实现的分布式任务队列解决方案，一般用于后台job，建议初学者选No
use_celery [n]: 
# 是否使用mailhog，mailhog是一个用于本地开发环境测试email的，建议初始选No
use_mailhog [n]: n
# 是否使用sentry，sentry是一个云端日志跟踪和分析平台，Python实现，同时也是开源平台，你可以自己搭建自己的sentry云日志跟踪分析平台。建议初始选No
use_sentry_for_error_reporting [y]: n
# 是否使用opbeat，opbeat是一个云端性能跟踪和分析工具，有一部分错误分析功能，建议初始选No
use_opbeat [n]: n
# 是否使用pycharm，pycharm是一个IDE，由大名鼎鼎的jetbrains公司出品，其出品其他有名的IDE如Idea，Webstorm等，因为我是pycharm开发所以选Yes，如果你不使用这个IDE则选No
use_pycharm [n]: y
# 是否是windows操作系统
windows [n]: n
# 是否使用Python3
use_python3 [y]: y
# 是否使用docker，docker是一个app容器平台，建议初始选No
use_docker [y]: n
# 是否使用heroku，heroku是一个PAAS云平台，用于部署web app，建议初始选No
use_heroku [n]: n
# 是否使用compressor，compressor是一个压缩解决方案，建议初始选No
use_compressor [n]: n
# 使用postgresql版本，这个项目建议本地开发环境和生产环境都使用Postgresql数据库，Postgresql是一个开源数据库，也是Django官方推荐使用的数据库，默认选择1为当前最新的版本。
Select postgresql_version:
1 - 9.5
2 - 9.4
3 - 9.3
4 - 9.2
Choose from 1, 2, 3, 4 [1]: 1
# 选择哪一种JavaScript任务管理器，这里建议初始选None，我们不希望在这里过多的涉及前端的内容。
Select js_task_runner:
1 - Gulp
2 - Grunt
3 - Webpack
4 - None
Choose from 1, 2, 3, 4 [1]: 4
# 是否使用let&#39;s encrypt，let&#39;s encrypt是一个免费生成SSL HTTPS证书的服务，让你的网站免费支持https安全协议，默认选No
use_lets_encrypt [n]: n
# 开源license，默认选1，如果你是私有项目，选5
Select open_source_license:
1 - MIT
2 - BSD
3 - GPLv3
4 - Apache Software License 2.0
5 - Not open source
Choose from 1, 2, 3, 4, 5 [1]: 1
是否使用AWS Elastic Beanstalk，默认选No
use_elasticbeanstalk_experimental: n
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Centos&#43;nginx&#43;uwsgi&#43;django</title>
      <link>http://danigong.github.io/post/django_uwsgi_nginx/</link>
      <pubDate>Sun, 24 Dec 2017 20:50:30 +0800</pubDate>
      
      <guid>http://danigong.github.io/post/django_uwsgi_nginx/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://uwsgi-docs.readthedocs.io/en/latest/tutorials/Django_and_nginx.html&#34;&gt;https://uwsgi-docs.readthedocs.io/en/latest/tutorials/Django_and_nginx.html&lt;/a&gt;
&lt;a href=&#34;http://www.jianshu.com/p/7494560da3e6&#34;&gt;http://www.jianshu.com/p/7494560da3e6&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This is our stack:&lt;/p&gt;

&lt;p&gt;the web client &amp;lt;-&amp;gt; the web server &amp;lt;-&amp;gt; the socket &amp;lt;-&amp;gt; uWSGI &amp;lt;-&amp;gt; Python&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Python Coroutine</title>
      <link>http://danigong.github.io/post/python_coroutine/</link>
      <pubDate>Mon, 15 Aug 2016 22:14:50 +0800</pubDate>
      
      <guid>http://danigong.github.io/post/python_coroutine/</guid>
      <description>

&lt;h2 id=&#34;协程:596b597b96b8798ca4833589eec0b9fc&#34;&gt;协程&lt;/h2&gt;

&lt;h3 id=&#34;协程-又称微线程-纤程-英文名coroutine:596b597b96b8798ca4833589eec0b9fc&#34;&gt;协程，又称微线程，纤程。英文名Coroutine。&lt;/h3&gt;

&lt;p&gt;协程的概念很早就提出来了，但直到最近几年才在某些语言（如Lua）中得到广泛应用。&lt;/p&gt;

&lt;p&gt;子程序，或者称为函数，在所有语言中都是层级调用，比如A调用B，B在执行过程中又调用了C，C执行完毕返回，B执行完毕返回，最后是A执行完毕。&lt;/p&gt;

&lt;p&gt;所以子程序调用是通过栈实现的，一个线程就是执行一个子程序。&lt;/p&gt;

&lt;p&gt;子程序调用总是一个入口，一次返回，调用顺序是明确的。而协程的调用和子程序不同。&lt;/p&gt;

&lt;p&gt;协程看上去也是子程序，但执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。&lt;/p&gt;

&lt;p&gt;注意，在一个子程序中中断，去执行其他子程序，不是函数调用，有点类似CPU的中断。比如子程序A、B：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def A():
    print &#39;1&#39;
    print &#39;2&#39;
    print &#39;3&#39;

def B():
    print &#39;x&#39;
    print &#39;y&#39;
    print &#39;z&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;假设由协程执行，在执行A的过程中，可以随时中断，去执行B，B也可能在执行过程中中断再去执行A，结果可能是：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1
2
x
y
3
z
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;但是在A中是没有调用B的，所以协程的调用比函数调用理解起来要难一些。&lt;/p&gt;

&lt;p&gt;看起来A、B的执行有点像多线程，但协程的特点在于是一个线程执行，那和多线程比，协程有何优势？&lt;/p&gt;

&lt;p&gt;最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。&lt;/p&gt;

&lt;p&gt;第二大优势就是不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。&lt;/p&gt;

&lt;p&gt;因为协程是一个线程执行，那怎么利用多核CPU呢？最简单的方法是多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。&lt;/p&gt;

&lt;p&gt;Python对协程的支持还非常有限，用在generator中的yield可以一定程度上实现协程。虽然支持不完全，但已经可以发挥相当大的威力了。&lt;/p&gt;

&lt;p&gt;来看例子：&lt;/p&gt;

&lt;p&gt;传统的生产者-消费者模型是一个线程写消息，一个线程取消息，通过锁机制控制队列和等待，但一不小心就可能死锁。&lt;/p&gt;

&lt;p&gt;如果改用协程，生产者生产消息后，直接通过yield跳转到消费者开始执行，待消费者执行完毕后，切换回生产者继续生产，效率极高：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import time

def consumer():
    r = &#39;&#39;
    while True:
        n = yield r
        if not n:
            return
        print(&#39;[CONSUMER] Consuming %s...&#39; % n)
        time.sleep(1)
        r = &#39;200 OK&#39;

def produce(c):
    c.next()
    n = 0
    while n &amp;lt; 5:
        n = n + 1
        print(&#39;[PRODUCER] Producing %s...&#39; % n)
        r = c.send(n)
        print(&#39;[PRODUCER] Consumer return: %s&#39; % r)
    c.close()

if __name__==&#39;__main__&#39;:
    c = consumer()
    produce(c)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[PRODUCER] Producing 1...
[CONSUMER] Consuming 1...
[PRODUCER] Consumer return: 200 OK
[PRODUCER] Producing 2...
[CONSUMER] Consuming 2...
[PRODUCER] Consumer return: 200 OK
[PRODUCER] Producing 3...
[CONSUMER] Consuming 3...
[PRODUCER] Consumer return: 200 OK
[PRODUCER] Producing 4...
[CONSUMER] Consuming 4...
[PRODUCER] Consumer return: 200 OK
[PRODUCER] Producing 5...
[CONSUMER] Consuming 5...
[PRODUCER] Consumer return: 200 OK
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意到consumer函数是一个generator（生成器），把一个consumer传入produce后：&lt;/p&gt;

&lt;p&gt;首先调用c.next()启动生成器；&lt;/p&gt;

&lt;p&gt;然后，一旦生产了东西，通过c.send(n)切换到consumer执行；&lt;/p&gt;

&lt;p&gt;consumer通过yield拿到消息，处理，又通过yield把结果传回；&lt;/p&gt;

&lt;p&gt;produce拿到consumer处理的结果，继续生产下一条消息；&lt;/p&gt;

&lt;p&gt;produce决定不生产了，通过c.close()关闭consumer，整个过程结束。&lt;/p&gt;

&lt;p&gt;整个流程无锁，由一个线程执行，produce和consumer协作完成任务，所以称为“协程”，而非线程的抢占式多任务。&lt;/p&gt;

&lt;p&gt;最后套用Donald Knuth的一句话总结协程的特点：&lt;/p&gt;

&lt;p&gt;“子程序就是协程的一种特例。”&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Python Generator</title>
      <link>http://danigong.github.io/post/python_generator/</link>
      <pubDate>Fri, 15 Jul 2016 22:07:29 +0800</pubDate>
      
      <guid>http://danigong.github.io/post/python_generator/</guid>
      <description>

&lt;hr /&gt;

&lt;h2 id=&#34;生成器:5a7c58757d5502c33c2b70739d3bc9d3&#34;&gt;生成器&lt;/h2&gt;

&lt;p&gt;通过列表生成式，我们可以直接创建一个列表。但是，受到内存限制，列表容量肯定是有限的。而且，创建一个包含100万个元素的列表，不仅占用很大的存储空间，如果我们仅仅需要访问前面几个元素，那后面绝大多数元素占用的空间都白白浪费了。&lt;/p&gt;

&lt;p&gt;所以，如果列表元素可以按照某种算法推算出来，那我们是否可以在循环的过程中不断推算出后续的元素呢？这样就不必创建完整的list，从而节省大量的空间。在Python中，这种一边循环一边计算的机制，称为生成器（Generator）。&lt;/p&gt;

&lt;p&gt;要创建一个generator，有很多种方法。第一种方法很简单，只要把一个列表生成式的[]改成()，就创建了一个generator：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; L = [x * x for x in range(10)]
&amp;gt;&amp;gt;&amp;gt; L
[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
&amp;gt;&amp;gt;&amp;gt; g = (x * x for x in range(10))
&amp;gt;&amp;gt;&amp;gt; g
&amp;lt;generator object &amp;lt;genexpr&amp;gt; at 0x104feab40&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;创建L和g的区别仅在于最外层的[]和()，L是一个list，而g是一个generator。&lt;/p&gt;

&lt;p&gt;我们可以直接打印出list的每一个元素，但我们怎么打印出generator的每一个元素呢？&lt;/p&gt;

&lt;p&gt;如果要一个一个打印出来，可以通过generator的next()方法：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; g.next()
0
&amp;gt;&amp;gt;&amp;gt; g.next()
1
&amp;gt;&amp;gt;&amp;gt; g.next()
4
&amp;gt;&amp;gt;&amp;gt; g.next()
9
&amp;gt;&amp;gt;&amp;gt; g.next()
16
&amp;gt;&amp;gt;&amp;gt; g.next()
25
&amp;gt;&amp;gt;&amp;gt; g.next()
36
&amp;gt;&amp;gt;&amp;gt; g.next()
49
&amp;gt;&amp;gt;&amp;gt; g.next()
64
&amp;gt;&amp;gt;&amp;gt; g.next()
81
&amp;gt;&amp;gt;&amp;gt; g.next()
Traceback (most recent call last):
  File &amp;quot;&amp;lt;stdin&amp;gt;&amp;quot;, line 1, in &amp;lt;module&amp;gt;
StopIteration
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们讲过，generator保存的是算法，每次调用next()，就计算出下一个元素的值，直到计算到最后一个元素，没有更多的元素时，抛出StopIteration的错误。&lt;/p&gt;

&lt;p&gt;当然，上面这种不断调用next()方法实在是太变态了，正确的方法是使用for循环，因为generator也是可迭代对象：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; g = (x * x for x in range(10))
&amp;gt;&amp;gt;&amp;gt; for n in g:
...     print n
...
0
1
4
9
16
25
36
49
64
81
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;所以，我们创建了一个generator后，基本上永远不会调用next()方法，而是通过for循环来迭代它。&lt;/p&gt;

&lt;p&gt;generator非常强大。如果推算的算法比较复杂，用类似列表生成式的for循环无法实现的时候，还可以用函数来实现。&lt;/p&gt;

&lt;p&gt;比如，著名的斐波拉契数列（Fibonacci），除第一个和第二个数外，任意一个数都可由前两个数相加得到：&lt;/p&gt;

&lt;p&gt;1, 1, 2, 3, 5, 8, 13, 21, 34, &amp;hellip;&lt;/p&gt;

&lt;p&gt;斐波拉契数列用列表生成式写不出来，但是，用函数把它打印出来却很容易：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def fib(max):
    n, a, b = 0, 0, 1
    while n &amp;lt; max:
        print b
        a, b = b, a + b
        n = n + 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的函数可以输出斐波那契数列的前N个数：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; fib(6)
1
1
2
3
5
8
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;仔细观察，可以看出，fib函数实际上是定义了斐波拉契数列的推算规则，可以从第一个元素开始，推算出后续任意的元素，这种逻辑其实非常类似generator。&lt;/p&gt;

&lt;p&gt;也就是说，上面的函数和generator仅一步之遥。要把fib函数变成generator，只需要把print b改为yield b就可以了：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def fib(max):
    n, a, b = 0, 0, 1
    while n &amp;lt; max:
        yield b
        a, b = b, a + b
        n = n + 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这就是定义generator的另一种方法。如果一个函数定义中包含yield关键字，那么这个函数就不再是一个普通函数，而是一个generator：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; fib(6)
&amp;lt;generator object fib at 0x104feaaa0&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里，最难理解的就是generator和函数的执行流程不一样。函数是顺序执行，遇到return语句或者最后一行函数语句就返回。而变成generator的函数，在每次调用next()的时候执行，遇到yield语句返回，再次执行时从上次返回的yield语句处继续执行。&lt;/p&gt;

&lt;p&gt;举个简单的例子，定义一个generator，依次返回数字1，3，5：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; def odd():
...     print &#39;step 1&#39;
...     yield 1
...     print &#39;step 2&#39;
...     yield 3
...     print &#39;step 3&#39;
...     yield 5
...
&amp;gt;&amp;gt;&amp;gt; o = odd()
&amp;gt;&amp;gt;&amp;gt; o.next()
step 1
1
&amp;gt;&amp;gt;&amp;gt; o.next()
step 2
3
&amp;gt;&amp;gt;&amp;gt; o.next()
step 3
5
&amp;gt;&amp;gt;&amp;gt; o.next()
Traceback (most recent call last):
  File &amp;quot;&amp;lt;stdin&amp;gt;&amp;quot;, line 1, in &amp;lt;module&amp;gt;
StopIteration
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到，odd不是普通函数，而是generator，在执行过程中，遇到yield就中断，下次又继续执行。执行3次yield后，已经没有yield可以执行了，所以，第4次调用next()就报错。&lt;/p&gt;

&lt;p&gt;回到fib的例子，我们在循环过程中不断调用yield，就会不断中断。当然要给循环设置一个条件来退出循环，不然就会产生一个无限数列出来。&lt;/p&gt;

&lt;p&gt;同样的，把函数改成generator后，我们基本上从来不会用next()来调用它，而是直接使用for循环来迭代：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; for n in fib(6):
...     print n
...
1
1
2
3
5
8
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;小结:5a7c58757d5502c33c2b70739d3bc9d3&#34;&gt;小结&lt;/h2&gt;

&lt;p&gt;generator是非常强大的工具，在Python中，可以简单地把列表生成式改成generator，也可以通过函数实现复杂逻辑的generator。&lt;/p&gt;

&lt;p&gt;要理解generator的工作原理，它是在for循环的过程中不断计算出下一个元素，并在适当的条件结束for循环。对于函数改成的generator来说，遇到return语句或者执行到函数体最后一行语句，就是结束generator的指令，for循环随之结束。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Machine Learning &amp; Deep Learning</title>
      <link>http://danigong.github.io/post/ML_materials/</link>
      <pubDate>Sun, 10 Jul 2016 14:03:09 +0800</pubDate>
      
      <guid>http://danigong.github.io/post/ML_materials/</guid>
      <description>

&lt;h3 id=&#34;机器学习-machine-learning-深度学习-deep-learning-资料-chapter-1:7f5176d6d6102fa1dc2184e7e7e36bd0&#34;&gt;机器学习(Machine Learning)&amp;amp;深度学习(Deep Learning)资料(Chapter 1)&lt;/h3&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;注-机器学习资料-篇目一-https-github-com-ty4z2008-qix-blob-master-dl-md-共500条-篇目二-https-github-com-ty4z2008-qix-blob-master-dl2-md-开始更新:7f5176d6d6102fa1dc2184e7e7e36bd0&#34;&gt;注:机器学习资料&lt;a href=&#34;https://github.com/ty4z2008/Qix/blob/master/dl.md&#34;&gt;篇目一&lt;/a&gt;共500条,&lt;a href=&#34;https://github.com/ty4z2008/Qix/blob/master/dl2.md&#34;&gt;篇目二&lt;/a&gt;开始更新&lt;/h3&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;希望转载的朋友-你可以不用联系我-但是-一定要保留原文链接-因为这个项目还在继续也在不定期更新-希望看到文章的朋友能够学到更多-此外-某些资料在中国访问需要梯子:7f5176d6d6102fa1dc2184e7e7e36bd0&#34;&gt;希望转载的朋友，你可以不用联系我．但是&lt;strong&gt;一定要保留原文链接&lt;/strong&gt;，因为这个项目还在继续也在不定期更新．希望看到文章的朋友能够学到更多．此外:某些资料在中国访问需要梯子.&lt;/h3&gt;

&lt;hr /&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.erogol.com/brief-history-machine-learning/&#34;&gt;《Brief History of Machine Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:这是一篇介绍机器学习历史的文章，介绍很全面，从感知机、神经网络、决策树、SVM、Adaboost到随机森林、Deep Learning.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.idsia.ch/~juergen/DeepLearning15May2014.pdf&#34;&gt;《Deep Learning in Neural Networks: An Overview》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:这是瑞士人工智能实验室Jurgen Schmidhuber写的最新版本《神经网络与深度学习综述》本综述的特点是以时间排序，从1940年开始讲起，到60-80年代，80-90年代，一直讲到2000年后及最近几年的进展。涵盖了deep learning里各种tricks，引用非常全面.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://machinelearningmastery.com/a-gentle-introduction-to-scikit-learn-a-python-machine-learning-library/&#34;&gt;《A Gentle Introduction to Scikit-Learn: A Python Machine Learning Library》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:这是一份python机器学习库,如果您是一位python工程师而且想深入的学习机器学习.那么这篇文章或许能够帮助到你.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://machinelearningmastery.com/how-to-layout-and-manage-your-machine-learning-project/&#34;&gt;《How to Layout and Manage Your Machine Learning Project》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:这一篇介绍如果设计和管理属于你自己的机器学习项目的文章，里面提供了管理模版、数据管理与实践方法.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/code-poet/80ea3ec3c471&#34;&gt;《Machine Learning is Fun!》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:如果你还不知道什么是机器学习，或则是刚刚学习感觉到很枯燥乏味。那么推荐一读。这篇文章已经被翻译成中文,如果有兴趣可以移步&lt;a href=&#34;http://blog.jobbole.com/67616/&#34;&gt;http://blog.jobbole.com/67616/&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://cran.r-project.org/doc/contrib/Liu-R-refcard.pdf&#34;&gt;《R语言参考卡片》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:R语言是机器学习的主要语言,有很多的朋友想学习R语言，但是总是忘记一些函数与关键字的含义。那么这篇文章或许能够帮助到你&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.echen.me/2011/04/27/choosing-a-machine-learning-classifier/&#34;&gt;《Choosing a Machine Learning Classifier》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:我该如何选择机器学习算法，这篇文章比较直观的比较了Naive Bayes，Logistic Regression，SVM，决策树等方法的优劣，另外讨论了样本大小、Feature与Model权衡等问题。此外还有已经翻译了的版本:&lt;a href=&#34;http://www.52ml.net/15063.html&#34;&gt;http://www.52ml.net/15063.html&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks&#34;&gt;《An Introduction to Deep Learning: From Perceptrons to Deep Networks》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：深度学习概述：从感知机到深度网络，作者对于例子的选择、理论的介绍都很到位，由浅入深。翻译版本：&lt;a href=&#34;http://www.cnblogs.com/xiaowanyer/p/3701944.html&#34;&gt;http://www.cnblogs.com/xiaowanyer/p/3701944.html&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://vdisk.weibo.com/s/ayG13we2vxyKl&#34;&gt;《The LION Way: Machine Learning plus Intelligent Optimization》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:&amp;lt;机器学习与优化&amp;gt;这是一本机器学习的小册子, 短短300多页道尽机器学习的方方面面. 图文并茂, 生动易懂, 没有一坨坨公式的烦恼. 适合新手入门打基础, 也适合老手温故而知新. 比起MLAPP/PRML等大部头, 也许这本你更需要!具体内容推荐阅读:&lt;a href=&#34;http://intelligent-optimization.org/LIONbook/&#34;&gt;http://intelligent-optimization.org/LIONbook/&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://php-52cs.rhcloud.com/?cat=7&#34;&gt;《深度学习与统计学习理论》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:作者是来自百度，不过他本人已经在2014年4月份申请离职了。但是这篇文章很不错如果你不知道深度学习与支持向量机/统计学习理论有什么联系？那么应该立即看看这篇文章.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-042j-mathematics-for-computer-science-fall-2010/readings/MIT6_042JF10_notes.pdf&#34;&gt;《计算机科学中的数学》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:这本书是由谷歌公司和MIT共同出品的计算机科学中的数学：&lt;a href=&#34;Mathematics for Computer Science&#34;&gt;Mathematics for Computer Science&lt;/a&gt;，Eric Lehman et al 2013 。分为5大部分：1）证明，归纳。2）结构，数论，图。3）计数，求和，生成函数。4）概率，随机行走。5）递归。等等&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://research.microsoft.com/en-US/people/kannan/book-no-solutions-aug-21-2014.pdf&#34;&gt;《信息时代的计算机科学理论(Foundations of Data Science)》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：信息时代的计算机科学理论,目前国内有纸质书购买，&lt;a href=&#34;https://itunes.apple.com/us/book/introduction-to-data-science/id529088127&#34;&gt;iTunes购买&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://vdisk.weibo.com/s/ayG13we2vx5qg&#34;&gt;《Data Science with R》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:这是一本由雪城大学新编的第二版《数据科学入门》教材：偏实用型，浅显易懂，适合想学习R语言的同学选读。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.informit.com/articles/article.aspx?p=2213858&#34;&gt;《Twenty Questions for Donald Knuth》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:这并不是一篇文档或书籍。这是篇向图灵奖得主Donald Knuth提问记录稿： 近日， Charles Leiserson, Al Aho, Jon Bentley等大神向Knuth提出了20个问题，内容包括TAOCP，P/NP问题，图灵机，逻辑，以及为什么大神不用电邮等等。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/pdf/1402.4304v2.pdf&#34;&gt;《Automatic Construction and Natural-Language Description of Nonparametric Regression Models》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：不会统计怎么办？不知道如何选择合适的统计模型怎么办？那这篇文章你的好好读一读了麻省理工Joshua B. Tenenbaum和剑桥Zoubin Ghahramani合作，写了一篇关于automatic statistician的文章。可以自动选择回归模型类别，还能自动写报告&amp;hellip;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://openreview.net/venue/iclr2014&#34;&gt;《ICLR 2014论文集》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:对深度学习和representation learning最新进展有兴趣的同学可以了解一下&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www-nlp.stanford.edu/IR-book/&#34;&gt;《Introduction to Information Retrieval》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：这是一本信息检索相关的书籍，是由斯坦福Manning与谷歌副总裁Raghavan等合著的Introduction to Information Retrieval一直是北美最受欢迎的信息检索教材之一。最近作者增加了该课程的幻灯片和作业。IR相关资源：&lt;a href=&#34;http://www-nlp.stanford.edu/IR-book/information-retrieval.html&#34;&gt;http://www-nlp.stanford.edu/IR-book/information-retrieval.html&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.denizyuret.com/2014/02/machine-learning-in-5-pictures.html&#34;&gt;《Machine learning in 10 pictures》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Deniz Yuret用10张漂亮的图来解释机器学习重要概念：1. Bias/Variance Tradeoff 2. Overfitting 3. Bayesian / Occam&amp;rsquo;s razor 4. Feature combination 5. Irrelevant feature 6. Basis function 7. Discriminative / Generative 8. Loss function 9. Least squares 10. Sparsity.很清晰&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://webscope.sandbox.yahoo.com/catalog.php?datatype=l&#34;&gt;《雅虎研究院的数据集汇总》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：雅虎研究院的数据集汇总： 包括语言类数据，图与社交类数据，评分与分类数据，计算广告学数据，图像数据，竞赛数据，以及系统类的数据。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www-bcf.usc.edu/~gareth/ISL/&#34;&gt;《An Introduction to Statistical Learning with Applications in R》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：这是一本斯坦福统计学著名教授Trevor Hastie和Robert Tibshirani的新书，并且在2014年一月已经开课：&lt;a href=&#34;https://class.stanford.edu/courses/HumanitiesScience/StatLearning/Winter2014/about&#34;&gt;https://class.stanford.edu/courses/HumanitiesScience/StatLearning/Winter2014/about&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://machinelearningmastery.com/best-machine-learning-resources-for-getting-started/&#34;&gt;Best Machine Learning Resources for Getting Started&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：机器学习最佳入门学习资料汇总是专为机器学习初学者推荐的优质学习资源，帮助初学者快速入门。而且这篇文章的介绍已经被翻译成&lt;a href=&#34;http://article.yeeyan.org/view/22139/410514&#34;&gt;中文版&lt;/a&gt;。如果你不怎么熟悉，那么我建议你先看一看中文的介绍。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.sina.com.cn/s/blog_bda0d2f10101fpp4.html&#34;&gt;My deep learning reading list&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:主要是顺着Bengio的PAMI review的文章找出来的。包括几本综述文章，将近100篇论文，各位山头们的Presentation。全部都可以在google上找到。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.morganclaypool.com/doi/abs/10.2200/S00266ED1V01Y201005HLT008?journalCode=hlt&#34;&gt;Cross-Language Information Retrieval&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：这是一本书籍，主要介绍的是跨语言信息检索方面的知识。理论很多&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.ibm.com/developerworks/cn/web/1103_zhaoct_recommstudy1/index.html?ca=drs-&#34;&gt;探索推荐引擎内部的秘密，第 1 部分: 推荐引擎初探&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:本文共有三个系列，作者是来自IBM的工程师。它主要介绍了推荐引擎相关算法，并帮助读者高效的实现这些算法。 &lt;a href=&#34;http://www.ibm.com/developerworks/cn/web/1103_zhaoct_recommstudy2/index.html?ca=drs-&#34;&gt;探索推荐引擎内部的秘密，第 2 部分: 深度推荐引擎相关算法 - 协同过滤&lt;/a&gt;,&lt;a href=&#34;http://www.ibm.com/developerworks/cn/web/1103_zhaoct_recommstudy3/index.html?ca=drs-&#34;&gt;探索推荐引擎内部的秘密，第 3 部分: 深度推荐引擎相关算法 - 聚类&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://mimno.infosci.cornell.edu/b/articles/ml-learn/&#34;&gt;《Advice for students of machine learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：康奈尔大学信息科学系助理教授David Mimno写的《对机器学习初学者的一点建议》， 写的挺实际，强调实践与理论结合，最后还引用了冯 • 诺依曼的名言: &amp;ldquo;Young man, in mathematics you don&amp;rsquo;t understand things. You just get used to them.&amp;rdquo;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://web.stanford.edu/group/pdplab/pdphandbook/&#34;&gt;分布式并行处理的数据&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：这是一本关于分布式并行处理的数据《Explorations in Parallel Distributed Processing: A Handbook of Models, Programs, and Exercises》,作者是斯坦福的James L. McClelland。着重介绍了各种神级网络算法的分布式实现,做Distributed Deep Learning 的童鞋可以参考下&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blogs.technet.com/b/machinelearning/archive/2014/07/01/what-is-machine-learning.aspx&#34;&gt;《“机器学习”是什么？》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:【“机器学习”是什么？】John Platt是微软研究院杰出科学家，17年来他一直在机器学习领域耕耘。近年来机器学习变得炙手可热，Platt和同事们遂决定开设&lt;a href=&#34;http://blogs.technet.com/b/machinelearning/&#34;&gt;博客&lt;/a&gt;，向公众介绍机器学习的研究进展。机器学习是什么，被应用在哪里？来看Platt的这篇&lt;a href=&#34;http://blogs.technet.com/b/machinelearning/archive/2014/07/01/what-is-machine-learning.aspx&#34;&gt;博文&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://icml.cc/2014/index/article/15.htm&#34;&gt;《2014年国际机器学习大会ICML 2014 论文》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：2014年国际机器学习大会（ICML）已经于6月21-26日在国家会议中心隆重举办。本次大会由微软亚洲研究院和清华大学联手主办，是这个有着30多年历史并享誉世界的机器学习领域的盛会首次来到中国，已成功吸引海内外1200多位学者的报名参与。干货很多，值得深入学习下&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blogs.technet.com/b/machinelearning/archive/2014/07/11/machine-learning-for-industry-a-case-study.aspx&#34;&gt;《Machine Learning for Industry: A Case Study》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：这篇文章主要是以Learning to Rank为例说明企业界机器学习的具体应用，RankNet对NDCG之类不敏感，加入NDCG因素后变成了LambdaRank，同样的思想从神经网络改为应用到Boosted Tree模型就成就了LambdaMART。&lt;a href=&#34;http://research.microsoft.com/en-us/people/cburges/?WT.mc_id=Blog_MachLearn_General_DI&#34;&gt;Chirs Burges&lt;/a&gt;，微软的机器学习大神，Yahoo 2010 Learning to Rank Challenge第一名得主，排序模型方面有RankNet，LambdaRank，LambdaMART，尤其以LambdaMART最为突出，代表论文为：
&lt;a href=&#34;http://research.microsoft.com/en-us/um/people/cburges/tech_reports/msr-tr-2010-82.pdf&#34;&gt;From RankNet to LambdaRank to LambdaMART: An Overview&lt;/a&gt;
此外，Burges还有很多有名的代表作，比如：&lt;a href=&#34;http://research.microsoft.com/pubs/67119/svmtutorial.pdf&#34;&gt;A Tutorial on Support Vector Machines for Pattern Recognition&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://research.microsoft.com/en-us/um/people/cburges/tech_reports/tr-2004-56.pdf&#34;&gt;Some Notes on Applied Mathematics for Machine Learning&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://meta-guide.com/software-meta-guide/100-best-github-deep-learning/&#34;&gt;100 Best GitHub: Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:100 Best GitHub: Deep Learning&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.52ml.net/12019.html&#34;&gt;《UFLDL-斯坦福大学Andrew Ng教授“Deep Learning”教程》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:本教程将阐述无监督特征学习和深度学习的主要观点。通过学习，你也将实现多个功能学习/深度学习算法，能看到它们为你工作，并学习如何应用/适应这些想法到新问题上。本教程假定机器学习的基本知识（特别是熟悉的监督学习，逻辑回归，梯度下降的想法），如果你不熟悉这些想法，我们建议你去这里&lt;a href=&#34;http://openclassroom.stanford.edu/MainFolder/CoursePage.php?course=MachineLearning&#34;&gt;机器学习课程&lt;/a&gt;，并先完成第II，III，IV章（到逻辑回归）。此外这关于这套教程的源代码在github上面已经有python版本了&lt;a href=&#34;https://github.com/jatinshah/ufldl_tutorial&#34;&gt; UFLDL Tutorial Code&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;*&lt;a href=&#34;http://research.microsoft.com/pubs/217165/ICASSP_DeepTextLearning_v07.pdf&#34;&gt;《Deep Learning for Natural Language Processing and Related Applications》&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;介绍:这份文档来自微软研究院,精髓很多。如果需要完全理解，需要一定的机器学习基础。不过有些地方会让人眼前一亮,毛塞顿开。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colah.github.io/posts/2014-07-Understanding-Convolutions/&#34;&gt;Understanding Convolutions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:这是一篇介绍图像卷积运算的文章，讲的已经算比较详细的了&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://mlss2014.com/&#34;&gt;《Machine Learning Summer School》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：每天请一个大牛来讲座，主要涉及机器学习，大数据分析，并行计算以及人脑研究。&lt;a href=&#34;https://www.youtube.com/user/smolix&#34;&gt;https://www.youtube.com/user/smolix&lt;/a&gt;    （需翻墙）&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/josephmisiti/awesome-machine-learning&#34;&gt;《Awesome Machine Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：一个超级完整的机器学习开源库总结，如果你认为这个碉堡了，那后面这个列表会更让你惊讶：【Awesome Awesomeness】,国内已经有热心的朋友进行了翻译&lt;a href=&#34;http://blog.jobbole.com/73806/&#34;&gt;中文介绍&lt;/a&gt;，&lt;a href=&#34;https://github.com/josephmisiti/awesome-machine-learning/blob/master/books.md&#34;&gt;机器学习数据挖掘免费电子书&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://cs224d.stanford.edu/syllabus.html&#34;&gt;斯坦福《自然语言处理》课程视频&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:ACL候任主席、斯坦福大学计算机系Chris Manning教授的《自然语言处理》课程所有视频已经可以在斯坦福公开课网站上观看了（如Chrome不行，可用IE观看） 作业与测验也可以下载。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://freemind.pluskid.org/machine-learning/deep-learning-and-shallow-learning/&#34;&gt;《Deep Learning and Shallow Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:对比 Deep Learning 和 Shallow Learning 的好文，来着浙大毕业、MIT 读博的 Chiyuan Zhang 的博客。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://benanne.github.io/2014/08/05/spotify-cnns.html&#34;&gt;《Recommending music on Spotify with deep learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:利用卷积神经网络做音乐推荐。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://neuralnetworksanddeeplearning.com/index.html&#34;&gt;《Neural Networks and Deep Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：神经网络的免费在线书，已经写了三章了，还有对应的开源代码：&lt;a href=&#34;https://github.com/mnielsen/neural-networks-and-deep-learning&#34;&gt;https://github.com/mnielsen/neural-networks-and-deep-learning&lt;/a&gt; 爱好者的福音。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://machinelearningmastery.com/java-machine-learning/&#34;&gt;《Java Machine Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：Java机器学习相关平台和开源的机器学习库，按照大数据、NLP、计算机视觉和Deep Learning分类进行了整理。看起来挺全的，Java爱好者值得收藏。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.oschina.net/translate/6-tips-for-writing-better-code&#34;&gt;《Machine Learning Theory: An Introductory Primer》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：机器学习最基本的入门文章，适合零基础者&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.ctocio.com/hotnews/15919.html&#34;&gt;《机器学习常见算法分类汇总》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：机器学习的算法很多。很多时候困惑人们都是，很多算法是一类算法，而有些算法又是从其他算法中延伸出来的。这里，我们从两个方面来给大家介绍，第一个方面是学习的方式，第二个方面是算法的类似性。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://suanfazu.com/discussion/68/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87survey%E5%90%88%E9%9B%86&#34;&gt;《机器学习经典论文/survey合集》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：看题目你已经知道了是什么内容,没错。里面有很多经典的机器学习论文值得仔细与反复的阅读。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://work.caltech.edu/library/&#34;&gt;《机器学习视频库》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：视频由加州理工学院（Caltech）出品。需要英语底子。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://suanfazu.com/discussion/109/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BB%8F%E5%85%B8%E4%B9%A6%E7%B1%8D&#34;&gt;《机器学习经典书籍》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：总结了机器学习的经典书籍，包括数学基础和算法理论的书籍，可做为入门参考书单。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://efytimes.com/e1/fullnews.asp?edid=121516&#34;&gt;《16 Free eBooks On Machine Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:16本机器学习的电子书，可以下载下来在pad，手机上面任意时刻去阅读。不多我建议你看完一本再下载一本。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.erogol.com/large-set-machine-learning-resources-beginners-mavens/&#34;&gt;《A Large set of Machine Learning Resources for Beginners to Mavens》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:标题很大，从新手到专家。不过看完上面所有资料。肯定是专家了&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://article.yeeyan.org/view/22139/410514&#34;&gt;《机器学习最佳入门学习资料汇总》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：入门的书真的很多，而且我已经帮你找齐了。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://users.soe.ucsc.edu/~niejiazhong/slides/chandra.pdf&#34;&gt;《Sibyl》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：Sibyl 是一个监督式机器学习系统，用来解决预测方面的问题，比如 YouTube 的视频推荐。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.slideshare.net/ssuser9cc1bd/piji-li-dltm&#34;&gt;《Neural Network &amp;amp; Text Mining》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:关于(Deep) Neural Networks在 NLP 和 Text Mining 方面一些paper的总结&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cnblogs.com/lxy2017/p/3927226.html&#34;&gt;《前景目标检测1（总结）》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:计算机视觉入门之前景目标检测1（总结）&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.52ml.net/17004.html&#34;&gt;《行人检测》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:计算机视觉入门之行人检测&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.kdnuggets.com/2014/08/deep-learning-important-resources-learning-understanding.html&#34;&gt;《Deep Learning – important resources for learning and understanding》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Important resources for learning and understanding . Is awesome&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.toptal.com/machine-learning/machine-learning-theory-an-introductory-primer&#34;&gt;《Machine Learning Theory: An Introductory Primer》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:这又是一篇机器学习初学者的入门文章。值得一读&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://neuralnetworksanddeeplearning.com/&#34;&gt;《Neural Networks and Deep Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:在线Neural Networks and Deep Learning电子书&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.52nlp.cn/python-%E7%BD%91%E9%A1%B5%E7%88%AC%E8%99%AB-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86-%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98&#34;&gt;《Python 网页爬虫 &amp;amp; 文本处理 &amp;amp; 科学计算 &amp;amp; 机器学习 &amp;amp; 数据挖掘兵器谱》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:python的17个关于机器学习的工具&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.flickering.cn/%E6%A6%82%E7%8E%87%E7%BB%9F%E8%AE%A1/2014/06/%E7%A5%9E%E5%A5%87%E7%9A%84%E4%BC%BD%E7%8E%9B%E5%87%BD%E6%95%B0%E4%B8%8A/&#34;&gt;《神奇的伽玛函数(上)》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:下集在这里&lt;a href=&#34;http://www.flickering.cn/%E6%A6%82%E7%8E%87%E7%BB%9F%E8%AE%A1/2014/06/%E7%A5%9E%E5%A5%87%E7%9A%84%E4%BC%BD%E7%8E%9B%E5%87%BD%E6%95%B0%E4%B8%8A/&#34;&gt;神奇的伽玛函数(下)&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://cxwangyi.github.io/notes/2014-01-20-distributed-machine-learning.html&#34;&gt;《分布式机器学习的故事》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:作者王益目前是腾讯广告算法总监，王益博士毕业后在google任研究。这篇文章王益博士7年来从谷歌到腾讯对于分布机器学习的所见所闻。值得细读&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://metacademy.org/roadmaps/cjrd/level-up-your-ml&#34;&gt;《机器学习提升之道（Level-Up Your Machine Learning）》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:把机器学习提升的级别分为0~4级，每级需要学习的教材和掌握的知识。这样，给机器学习者提供一个上进的路线图，以免走弯路。另外，整个网站都是关于机器学习的，资源很丰富。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.mlsurveys.com/&#34;&gt;《Machine Learning Surveys》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:机器学习各个方向综述的网站&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://deeplearning.net/reading-list/&#34;&gt;《Deep Learning Reading list》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:深度学习阅资源列表&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://research.microsoft.com/pubs/219984/DeepLearningBook_RefsByLastFirstNames.pdf&#34;&gt;《Deep Learning: Methods and Applications》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：这是一本来自微的研究员 li Peng和Dong Yu所著的关于深度学习的方法和应用的电子书&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://pan.baidu.com/s/1pJ0ok7T&#34;&gt;《Machine Learning Summer School 2014》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:2014年七月CMU举办的机器学习夏季课刚刚结束 有近50小时的视频、十多个PDF版幻灯片，覆盖 深度学习，贝叶斯，分布式机器学习，伸缩性 等热点话题。所有13名讲师都是牛人：包括大牛Tom Mitchell （他的［机器学习］是名校的常用教材），还有CMU李沐 .（1080P高清哟）&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://users.soe.ucsc.edu/~niejiazhong/slides/chandra.pdf&#34;&gt;《Sibyl: 来自Google的大规模机器学习系统》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:在今年的IEEE/IFIP可靠系统和网络（DSN）国际会议上，Google软件工程师Tushar Chandra做了一个关于Sibyl系统的主题演讲。 Sibyl是一个监督式机器学习系统，用来解决预测方面的问题，比如YouTube的视频推荐。详情请阅读&lt;a href=&#34;http://www.infoq.com/cn/news/2014/07/google-sibyl&#34;&gt;google sibyl&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://googleresearch.blogspot.com/2014/09/building-deeper-understanding-of-images.html&#34;&gt;《Building a deeper understanding of images》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:谷歌研究院的Christian Szegedy在谷歌研究院的博客上简要地介绍了他们今年参加ImageNet取得好成绩的GoogLeNet系统.是关于图像处理的。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/memect/hao/blob/master/awesome/bayesian-network-python.md&#34;&gt;《Bayesian network 与python概率编程实战入门》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:贝叶斯学习。如果不是很清可看看&lt;a href=&#34;http://www.infoq.com/cn/news/2014/07/programming-language-bayes&#34;&gt;概率编程语言与贝叶斯方法实践&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.reddit.com/r/MachineLearning/comments/2fxi6v/ama_michael_i_jordan/&#34;&gt;《AMA: Michael I Jordan》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:网友问伯克利机器学习大牛、美国双料院士Michael I. Jordan：&amp;rdquo;如果你有10亿美金，你怎么花？Jordan: &amp;ldquo;我会用这10亿美金建造一个NASA级别的自然语言处理研究项目。&amp;rdquo;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cnblogs.com/tornadomeet/p/3395593.html&#34;&gt;《机器学习&amp;amp;数据挖掘笔记_16（常见面试之机器学习算法思想简单梳理）》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:常见面试之机器学习算法思想简单梳理,此外作者还有一些其他的&lt;a href=&#34;http://www.cnblogs.com/tornadomeet/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/&#34;&gt;机器学习与数据挖掘文章&lt;/a&gt;和&lt;a href=&#34;http://www.cnblogs.com/tornadomeet/tag/Deep%E3%80%80Learning/&#34;&gt;深度学习文章&lt;/a&gt;,不仅是理论还有源码。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.kdnuggets.com/2014/09/most-viewed-web-mining-lectures-videolectures.html&#34;&gt;《文本与数据挖掘视频汇总》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：Videolectures上最受欢迎的25个文本与数据挖掘视频汇总&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://timdettmers.wordpress.com/2014/08/14/which-gpu-for-deep-learning/&#34;&gt;《怎么选择深度学习的GPUs》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:在Kaggle上经常取得不错成绩的Tim Dettmers介绍了他自己是怎么选择深度学习的GPUs, 以及个人如何构建深度学习的GPU集群: &lt;a href=&#34;http://t.cn/RhpuD1G&#34;&gt;http://t.cn/RhpuD1G&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.infoq.com/cn/news/2014/09/depth-model&#34;&gt;《对话机器学习大神Michael Jordan：深度模型》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:对话机器学习大神Michael Jordan&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.sina.com.cn/s/blog_46d0a3930101fswl.html&#34;&gt;《Deep Learning 和 Knowledge Graph 引爆大数据革命》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:还有２，３部分。&lt;a href=&#34;http://blog.sina.com.cn/s/blog_46d0a3930101gs5h.html&#34;&gt;http://blog.sina.com.cn/s/blog_46d0a3930101gs5h.html&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.sina.com.cn/s/blog_46d0a3930101h6nf.html&#34;&gt;《Deep Learning 教程翻译》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:是Stanford 教授 Andrew Ng 的 Deep Learning 教程，国内的机器学习爱好者很热心的把这个教程翻译成了中文。如果你英语不好，可以看看这个&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://markus.com/deep-learning-101/&#34;&gt;《Deep Learning 101》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:因为近两年来，深度学习在媒体界被炒作很厉害（就像大数据）。其实很多人都还不知道什么是深度学习。这篇文章由浅入深。告诉你深度学究竟是什么！&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://ufldl.stanford.edu/wiki/index.php/UFLDL_Tutorial&#34;&gt;《UFLDL Tutorial》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:这是斯坦福大学做的一免费课程（很勉强），这个可以给你在深度学习的路上给你一个学习的思路。里面提到了一些基本的算法。而且告诉你如何去应用到实际环境中。&lt;a href=&#34;http://ufldl.stanford.edu/wiki/index.php/UFLDL%E6%95%99%E7%A8%8B&#34;&gt;中文版&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://deeplearning.cs.toronto.edu/&#34;&gt;《Toronto Deep Learning Demos》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:这是多伦多大学做的一个深度学习用来识别图片标签／图转文字的demo。是一个实际应用案例。有源码&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://metacademy.org/roadmaps/rgrosse/deep_learning&#34;&gt;《Deep learning from the bottom up》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:机器学习模型，阅读这个内容需要有一定的基础。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://cran.r-project.org/web/views/&#34;&gt;《R工具包的分类汇总》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: (CRAN Task Views, 34种常见任务,每个任务又各自分类列举若干常用相关工具包) 例如: 机器学习，自然语言处理，时间序列分析，空间信息分析，多重变量分析，计量经济学，心理统计学，社会学统计，化学计量学，环境科学，药物代谢动力学 等&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.ctocio.com/hotnews/15919.html&#34;&gt;《机器学习常见算法分类汇总》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 机器学习无疑是当前数据分析领域的一个热点内容。很多人在平时的工作中都或多或少会用到机器学习的算法。本文为您总结一下常见的机器学习算法，以供您在工作和学习中参考.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.csdn.net/zouxy09/article/details/8775360&#34;&gt;《Deep Learning（深度学习）学习笔记整理系列》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 很多干货，而且作者还总结了好几个系列。另外还作者还了一个&lt;a href=&#34;http://blog.csdn.net/zouxy09/article/details/14222605&#34;&gt;文章导航&lt;/a&gt;.非常的感谢作者总结。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.csdn.net/zouxy09/article/details/8775488&#34;&gt;Deep Learning（深度学习）学习笔记整理系列之（二）&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.csdn.net/zouxy09/article/details/8775518&#34;&gt;Deep Learning（深度学习）学习笔记整理系列之（三）&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.csdn.net/zouxy09/article/details/8775524&#34;&gt;Deep Learning（深度学习）学习笔记整理系列之（四）&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.csdn.net/zouxy09/article/details/8777094&#34;&gt;Deep Learning（深度学习）学习笔记整理系列之（五）&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.csdn.net/zouxy09/article/details/8781396&#34;&gt;Deep Learning（深度学习）学习笔记整理系列之（六）&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.csdn.net/zouxy09/article/details/8781543&#34;&gt;Deep Learning（深度学习）学习笔记整理系列之（七）&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.csdn.net/zouxy09/article/details/8782018&#34;&gt;DeepLearning（深度学习）学习笔记整理系列之（八）&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://research.microsoft.com/apps/video/default.aspx?id=206976&amp;amp;l=i&#34;&gt;《Tutorials Session A - Deep Learning for Computer Vision》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:传送理由：Rob Fergus的用深度学习做计算机是觉的NIPS 2013教程。有mp4, mp3, pdf各种&lt;a href=&#34;http://msrvideo.vo.msecnd.net/rmcvideos/206976/dl/206976.pdf&#34;&gt;下载&lt;/a&gt; 他是纽约大学教授，目前也在Facebook工作，他2014年的8篇&lt;a href=&#34;http://cs.nyu.edu/~fergus/pmwiki/pmwiki.php?n=PmWiki.Publications&#34;&gt;论文&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/xpqiu/fnlp/&#34;&gt;《FudanNLP》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:FudanNLP，这是一个复旦大学计算机学院开发的开源中文自然语言处理（NLP）工具包
Fudan NLP里包含中文分词、关键词抽取、命名实体识别、词性标注、时间词抽取、语法分析等功能，对搜索引擎 文本分析等极为有价值。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://engineering.linkedin.com/large-scale-machine-learning/open-sourcing-ml-ease&#34;&gt;《Open Sourcing ml-ease》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:LinkedIn 开源的机器学习工具包,支持单机, Hadoop cluster，和 Spark cluster 重点是 logistic regression 算法&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://ztl2004.github.io/MachineLearningWeekly/index.html&#34;&gt;《机器学习周刊》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:对于英语不好，但又很想学习机器学习的朋友。是一个大的福利。机器学习周刊目前主要提供中文版，还是面向广大国内爱好者，内容涉及机器学习、数据挖掘、并行系统、图像识别、人工智能、机器人等等。谢谢作者&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://v.163.com/special/opencourse/daishu.html&#34;&gt;《线性代数》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：《线性代数》是《机器学习》的重要数学先导课程。其实《线代》这门课讲得浅显易懂特别不容易，如果一上来就讲逆序数及罗列行列式性质，很容易让学生失去学习的兴趣。我个人推荐的最佳《线性代数》课程是麻省理工Gilbert Strang教授的课程。 &lt;a href=&#34;http://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/&#34;&gt;课程主页&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.andreamostosi.name/big-data/&#34;&gt;《Big-data》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:大数据数据处理资源、工具不完备列表，从框架、分布式编程、分布式文件系统、键值数据模型、图数据模型、数据可视化、列存储、机器学习等。很赞的资源汇总。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://yahoolabs.tumblr.com/post/97839313996/machine-learning-for-smart-dummies&#34;&gt;《machine learning for smart dummies》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:雅虎邀请了一名来自本古里安大学的访问学者，制作了一套关于机器学习的系列视频课程。本课程共分为7期，详细讲解了有关SVM, boosting, nearest neighbors, decision trees 等常规机器学习算法的理论基础知识。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1409.7770&#34;&gt;《Entanglement-Based Quantum Machine Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:应对大数据时代，量子机器学习的第一个实验 &lt;a href=&#34;http://arxiv-web3.library.cornell.edu/pdf/1409.7770.pdf&#34;&gt;paper 下载&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.wired.com/2014/01/how-to-hack-okcupid/all/&#34;&gt;《How a Math Genius Hacked OkCupid to Find True Love》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Wired杂志报道了UCLA数学博士Chris McKinlay （图1）通过大数据手段+机器学习方法破解婚恋网站配对算法找到真爱的故事,通过Python脚本控制着12个账号，下载了婚恋网站2万女用户的600万问题答案，对他们进行了统计抽样及聚类分析（图2，3），最后终于收获了真爱。科技改变命运！&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.edx.org/course/mitx/mitx-6-832x-underactuated-robotics-3511&#34;&gt;《Underactuated Robotics》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:MIT的Underactuated Robotics于 2014年10月1日开课，该课属于MIT研究生级别的课程，对机器人和非线性动力系统感兴趣的朋友不妨可以挑战一下这门课程！&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://yanbohappy.sinaapp.com/?p=498&#34;&gt;《mllib实践经验(1)》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:mllib实践经验分享&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.seobythesea.com/2014/09/google-turns-deep-learning-classification-fight-web-spam/&#34;&gt;《Google Turns To Deep Learning Classification To Fight Web Spam》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Google用Deep Learning做的antispam(反垃圾邮件)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/memect/hao/blob/master/awesome/nlp.md&#34;&gt;《NLP常用信息资源》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:NLP常用信息资源* &lt;a href=&#34;https://github.com/memect/hao/blob/master/awesome/nlp.md&#34;&gt;《NLP常用信息资源》&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/soulmachine/machine-learning-cheat-sheet&#34;&gt;《机器学习速查表》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:机器学习速查表&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arnetminer.org/conferencebestpapers&#34;&gt;《Best Papers vs. Top Cited Papers in Computer Science》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：从1996年开始在计算机科学的论文中被引用次数最多的论文&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://mmcheng.net/zh/itam/&#34;&gt;《InfiniTAM: 基于深度图像的体数据集成框架》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：把今年的一个ACM Trans. on Graphics (TOG)论文中的代码整理为一个开源的算法框架，共享出来了。欢迎大家使用。可以实时的采集3D数据、重建出三维模型。Online learning，GPU Random forest，GPU CRF也会后续公开。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://karpathy.github.io/neuralnets/&#34;&gt;《Hacker&amp;rsquo;s guide to Neural Networks》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：【神经网络黑客指南】现在，最火莫过于深度学习（Deep Learning），怎样更好学习它？可以让你在浏览器中，跑起深度学习效果的超酷开源项目&lt;a href=&#34;https://github.com/karpathy/convnetjs&#34;&gt;ConvNetJS&lt;/a&gt;作者karpathy告诉你，最佳技巧是，当你开始写代码，一切将变得清晰。他刚发布了一本图书，不断在线更新&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://machinelearningmastery.com/building-a-production-machine-learning-infrastructure/&#34;&gt;《Building a Production Machine Learning Infrastructure》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：前Google广告系统工程师Josh Wills 讲述工业界和学术界机器学习的异同,大实话&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://neo4j.com/blog/deep-learning-sentiment-analysis-movie-reviews-using-neo4j/&#34;&gt;《Deep Learning Sentiment Analysis for Movie Reviews using Neo4j》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：使用&lt;a href=&#34;http://www.neo4j.org/&#34;&gt;Neo4j&lt;/a&gt; 做电影评论的情感分析。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://memkite.com/deep-learning-bibliography/&#34;&gt;《DeepLearning.University – An Annotated Deep Learning Bibliography》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：不仅是资料，而且还对有些资料做了注释。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.datarobot.com/blog/a-primer-on-deep-learning/&#34;&gt;《A primer on deeping learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：深度学习入门的初级读本&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://news.ycombinator.com/item?id=8379571&#34;&gt;《Machine learning is teaching us the secret to teaching 》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：机器学习教会了我们什么？&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://scikit-learn.org/stable/documentation.html&#34;&gt;《scikit-learn：用于机器学习的Python模块》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：scikit-learn是在SciPy基础上构建的用于机器学习的Python模块。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.infoq.com/cn/news/2014/10/interview-michael-jordan&#34;&gt;《对话机器学习大神Michael Jordan：解析领域中各类模型》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：乔丹教授（Michael I. Jordan）教授是机器学习领域神经网络的大牛，他对深度学习、神经网络有着很浓厚的兴趣。因此，很多提问的问题中包含了机器学习领域的各类模型，乔丹教授对此一一做了解释和展望。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.redblobgames.com/pathfinding/a-star/introduction.html&#34;&gt;《A*搜索算法的可视化短教程》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：A*搜索是人工智能基本算法，用于高效地搜索图中两点的最佳路径, 核心是 g(n)+h(n): g(n)是从起点到顶点n的实际代价，h(n)是顶点n到目标顶点的估算代价。&lt;a href=&#34;https://github.com/memect/hao/issues/256&#34;&gt;合集&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://code.csdn.net/news/2822123&#34;&gt;《基于云的自然语言处理开源项目FudanNLP》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：本项目利用了Microsoft Azure，可以在几分种内完成NLP on Azure Website的部署，立即开始对FNLP各种特性的试用，或者以REST API的形式调用FNLP的语言分析功能&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.youku.com/playlist_show/id_22935176.html&#34;&gt;《吴立德《概率主题模型&amp;amp;数据科学基础》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：现任复旦大学首席教授、计算机软件博士生导师。计算机科学研究所副所长.内部课程&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://ml.memect.com/article/machine-learning-guide.html&#34;&gt;《机器学习入门资源不完全汇总》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：好东西的干货真的很多&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://memkite.com/deep-learning-bibliography/&#34;&gt;《收集从2014年开始深度学习文献》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：从硬件、图像到健康、生物、大数据、生物信息再到量子计算等，Amund Tveit等维护了一个DeepLearning.University小项目：收集从2014年开始深度学习文献，相信可以作为深度学习的起点,&lt;a href=&#34;https://github.com/memkite/DeepLearningBibliography&#34;&gt;github&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://emnlp2014.org/papers/pdf/EMNLP2014148.pdf&#34;&gt;《EMNLP上两篇关于股票趋势的应用论文 》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：EMNLP上两篇关于&lt;a href=&#34;http://emnlp2014.org/papers/pdf/EMNLP2014148.pdf&#34;&gt;stock trend&lt;/a&gt; 用到了deep model组织特征；&lt;a href=&#34;http://emnlp2014.org/papers/pdf/EMNLP2014120.pdf&#34;&gt; Exploiting Social Relations and Sentiment for Stock Prediction&lt;/a&gt;用到了stock network。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://deeplearning.net/tutorial/deeplearning.pdf&#34;&gt;《Bengio组（蒙特利尔大学LISA组）深度学习教程 》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：作者是深度学习一线大牛Bengio组写的教程，算法深入显出，还有实现代码，一步步展开。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/pdf/1410.5401v1.pdf&#34;&gt;《学习算法的Neural Turing Machine 》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：许多传统的机器学习任务都是在学习function，不过谷歌目前有开始学习算法的趋势。谷歌另外的这篇学习Python程序的&lt;a href=&#34;http://arxiv.org/pdf/1410.4615v1.pdf&#34;&gt;Learning to Execute&lt;/a&gt;也有相似之处&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.morganclaypool.com/doi/abs/10.2200/S00607ED2V01Y201410HLT026&#34;&gt;《Learning to Rank for Information Retrieval and Natural Language Processing》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：作者是华为技术有限公司，诺亚方舟实验室，首席科学家的李航博士写的关于信息检索与自然语言处理的文章&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.aclweb.org/anthology/D11-1147&#34;&gt;《Rumor has it: Identifying Misinformation in Microblogs》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：利用机用器学习在谣言的判别上的应用,此外还有两个。一个是识别垃圾与虚假信息的&lt;a href=&#34;http://digital.cs.usu.edu/~kyumin/tutorial/www-tutorial.pdf&#34;&gt;paper&lt;/a&gt;.还有一个是&lt;a href=&#34;http://www.datatang.com/news/details_1319.htm&#34;&gt;网络舆情及其分析技术&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://study.163.com/course/introduction/854064.htm&#34;&gt;《R机器学习实践》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：该课程是网易公开课的收费课程，不贵，超级便宜。主要适合于对利用R语言进行机器学习，数据挖掘感兴趣的人。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://ifeve.com/bigdataanalyticsbeyondhadoop_evolutionofmlrealizaton/&#34;&gt;《大数据分析：机器学习算法实现的演化》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：本章中作者总结了三代机器学习算法实现的演化：第一代非分布式的， 第二代工具如Mahout和Rapidminer实现基于Hadoop的扩展，第三代如Spark和Storm实现了实时和迭代数据处理。&lt;a href=&#34;http://ifeve.com/wp-content/uploads/2014/05/big-data-analytics-beyond-hadoop.pdf&#34;&gt;BIG DATA ANALYTICS BEYOND HADOOP&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://book.douban.com/subject/5921462/&#34;&gt;《图像处理，分析与机器视觉》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：讲计算机视觉的四部奇书（应该叫经典吧）之一，另外三本是Hartley的《多图几何》、Gonzalez的《数字图像处理》、Rafael C.Gonzalez / Richard E.Woods 的&lt;a href=&#34;http://book.douban.com/subject/1106342/&#34;&gt;《数字图像处理》&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://pan.baidu.com/s/1sjFeLTN&#34;&gt;《LinkedIn最新的推荐系统文章Browsemaps》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：里面基本没涉及到具体算法，但作者介绍了CF在LinkedIn的很多应用，以及他们在做推荐过程中获得的一些经验。最后一条经验是应该监控log数据的质量，因为推荐的质量很依赖数据的质量！&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.sina.com.cn/s/blog_574a437f01019poo.html&#34;&gt;《初学者如何查阅自然语言处理（NLP）领域学术资料》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：初学者如何查阅自然语言处理（NLP）领域学术资料&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.open-electronics.org/raspberry-pi-and-the-camera-pi-module-face-recognition-tutorial/&#34;&gt;《树莓派的人脸识别教程》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：用树莓派和相机模块进行人脸识别&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.hangli-hl.com/uploads/3/1/6/8/3168008/short_text_conversation_mla.pdf&#34;&gt;《利用深度学习与大数据构建对话系统  》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：如何利用深度学习与大数据构建对话系统&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://lear.inrialpes.fr/people/mairal/resources/pdf/review_sparse_arxiv.pdf&#34;&gt;《经典论文Leo Breiman：Statistical Modeling: The Two Cultures  》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：Francis Bach合作的有关稀疏建模的新综述(书)：Sparse Modeling for Image and Vision Processing，内容涉及Sparsity, Dictionary Learning, PCA, Matrix Factorization等理论，以及在图像和视觉上的应用，而且第一部分关于Why does the l1-norm induce sparsity的解释也很不错。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.umiacs.umd.edu/~hal/docs/daume04rkhs.pdf&#34;&gt;《Reproducing Kernel Hilbert Space》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：RKHS是机器学习中重要的概念，其在large margin分类器上的应用也是广为熟知的。如果没有较好的数学基础，直接理解RKHS可能会不易。本文从基本运算空间讲到Banach和Hilbert空间，深入浅出，一共才12页。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://karpathy.github.io/neuralnets/&#34;&gt;《Hacker&amp;rsquo;s guide to Neural Networks》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：许多同学对于机器学习及深度学习的困惑在于，数学方面已经大致理解了，但是动起手来却不知道如何下手写代码。斯坦福深度学习博士Andrej Karpathy写了一篇实战版本的深度学习及机器学习教程，手把手教你用Javascript写神经网络和SVM.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.csdn.net/pandalibaba/article/details/17409395&#34;&gt;《【语料库】语料库资源汇总》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：【语料库】语料库资源汇总&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.jobbole.com/60809/&#34;&gt;《机器学习算法之旅》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：本文会过一遍最流行的机器学习算法，大致了解哪些方法可用，很有帮助。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.csee.wvu.edu/~xinl/source.html&#34;&gt;《Reproducible Research in Computational Science》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：这个里面有很多关于机器学习、信号处理、计算机视觉、深入学习、神经网络等领域的大量源代码（或可执行代码）及相关论文。科研写论文的好资源&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://cilvr.nyu.edu/doku.php?id=deeplearning:slides:start&#34;&gt;《NYU 2014年的深度学习课程资料》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：NYU 2014年的深度学习课程资料，有视频&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/memect/hao/blob/master/awesome/computer-vision-dataset.md&#34;&gt;《计算机视觉数据集不完全汇总》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：计算机视觉数据集不完全汇总&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://mloss.org/software/&#34;&gt;《Machine Learning Open Source Software》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：机器学习开源软件&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&#34;&gt;《LIBSVM》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：A Library for Support Vector Machines&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.support-vector-machines.org/index.html&#34;&gt;《Support Vector Machines》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：&lt;a href=&#34;files.cnblogs.com/tekson/数据挖掘之经典算法.doc&#34;&gt;数据挖掘十大经典算法&lt;/a&gt;之一&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://meta-guide.com/software-meta-guide/100-best-github-deep-learning/&#34;&gt;《100 Best GitHub: Deep Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：github上面100个非常棒的项目&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://archive.ics.uci.edu/ml&#34;&gt;《加州大学欧文分校(UCI)机器学习数据集仓库》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：当前加州大学欧文分校为机器学习社区维护着306个数据集。&lt;a href=&#34;http://archive.ics.uci.edu/ml/datasets.html&#34;&gt;查询数据集&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://cs.stanford.edu/people/karpathy/&#34;&gt;《Andrej Karpathy个人主页》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：Andrej Karpathy 是斯坦福大学Li Fei-Fei的博士生，使用机器学习在图像、视频语义分析领域取得了科研和工程上的突破，发的文章不多，但每个都很扎实，在每一个问题上都做到了state-of-art.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://cs.stanford.edu/people/karpathy/convnetjs/demo/rldemo.html&#34;&gt;《Andrej Karpathy的深度强化学习演示》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：Andrej Karpathy的深度强化学习演示，&lt;a href=&#34;http://arxiv.org/pdf/1312.5602v1.pdf&#34;&gt;论文在这里&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.52nlp.cn/cikm-competition-topdata&#34;&gt;《CIKM数据挖掘竞赛夺冠算法-陈运文》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：CIKM Cup(或者称为CIKM Competition)是ACM CIKM举办的国际数据挖掘竞赛的名称。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cs.toronto.edu/~hinton/&#34;&gt;《Geoffrey E. Hinton》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：杰弗里·埃弗里斯特·辛顿 FRS是一位英国出生的计算机学家和心理学家，以其在神经网络方面的贡献闻名。辛顿是反向传播算法和对比散度算法的发明人之一，也是深度学习的积极推动者.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://cikm2014.fudan.edu.cn/cikm2014/Tpl/Public/slides/CIKM14_tutorial_slides_6.pdf&#34;&gt;《自然语言处理的深度学习理论与实际》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：微软研究院深度学习技术中心在CIKM2014 上关于《自然语言处理的深度学习理论与实际》教学讲座的幻灯片&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://eugenezhulenev.com/blog/2014/11/14/stock-price-prediction-with-big-data-and-machine-learning/&#34;&gt;《用大数据和机器学习做股票价格预测》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍： 本文基于&amp;lt;支持向量机的高频限价订单的动态建模&amp;gt;采用了 Apache Spark和Spark MLLib从纽约股票交易所的订单日志数据构建价格运动预测模型。(股票有风险，投资谨慎)GitHub源代码托管&lt;a href=&#34;https://github.com/ezhulenev/orderbook-dynamics&#34;&gt;地址&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://dataunion.org/?p=2011&#34;&gt;《关于机器学习的若干理论问题》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：徐宗本 院士将于热爱机器学习的小伙伴一起探讨有关于机器学习的几个理论性问题，并给出一些有意义的结论。最后通过一些实例来说明这些理论问题的物理意义和实际应用价值。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://vdisk.weibo.com/s/D2szyg_bBVM0&#34;&gt;《深度学习在自然语言处理的应用》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：作者还著有《这就是搜索引擎：核心技术详解》一书，主要是介绍应用层的东西&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cs.ubc.ca/~nando/340-2012/index.php&#34;&gt;《Undergraduate machine learning at UBC》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：机器学习课程&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.sina.com.cn/s/blog_6ae183910101h4jr.html&#34;&gt;《人脸识别必读的N篇文章》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：人脸识别必读文章推荐&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://semocean.com/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E6%96%87%E7%8C%AE%E5%8F%8A%E8%B5%84%E6%96%99/&#34;&gt;《推荐系统经典论文文献及业界应用》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：推荐系统经典论文文献&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.sina.com.cn/s/blog_6ae183910101h4jr.html&#34;&gt;《人脸识别必读的N篇文章》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：人脸识别必读文章推荐&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://see.xidian.edu.cn/vipsl/MLA2014/program.htm&#34;&gt;《第十二届中国&amp;rdquo;机器学习及其应用&amp;rdquo;研讨会PPT》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：第十二届中国&amp;rdquo;机器学习及其应用&amp;rdquo;研讨会PPT&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://ocw.sjtu.edu.cn/G2S/OCW/cn/CourseDetails.htm?Id=398&#34;&gt;《统计机器学习》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：统计学习是关于计算机基于数据构建的概率统计模型并运用模型对数据进行预测和分析的一门科学，统计学习也成为统计机器学习。课程来自上海交通大学&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://ocw.sjtu.edu.cn/G2S/OCW/cn/CourseDetails.htm?Id=397&#34;&gt;《机器学习导论》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：机器学习的目标是对计算机编程，以便使用样本数据或以往的经验来解决给定的问题.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://cikm2014.fudan.edu.cn/&#34;&gt;《CIKM 2014主题报告的幻灯片》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：CIKM 2014 Jeff Dean、Qi Lu、Gerhard Weikum的主题报告的幻灯片， Alex Smola、Limsoon Wong、Tong Zhang、Chih-Jen Lin的Industry Track报告的幻灯片&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://deeplearning.net/software_links/&#34;&gt;《人工智能和机器学习领域有趣的开源项目》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：部分中文&lt;a href=&#34;http://code.csdn.net/news/2822818&#34;&gt;列表&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.csdn.net/suipingsp/article/details/41645779&#34;&gt;《机器学习经典算法详解及Python实现&amp;ndash;基于SMO的SVM分类器》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:此外作者还有一篇&lt;a href=&#34;http://blog.csdn.net/suipingsp/article/details/41722435&#34;&gt;元算法、AdaBoost　python实现文章&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://aria42.com/blog/2014/12/understanding-lbfgs/&#34;&gt;《Numerical Optimization: Understanding L-BFGS》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:加州伯克利大学博士Aria Haghighi写了一篇超赞的数值优化博文，从牛顿法讲到拟牛顿法，再讲到BFGS以及L-BFGS, 图文并茂，还有伪代码。强烈推荐。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.goldencui.org/2014/12/02/%E7%AE%80%E6%98%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%A6%82%E8%BF%B0%EF%BC%88%E4%B8%80%EF%BC%89/&#34;&gt;《简明深度学习方法概述（一）》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:还有续集&lt;a href=&#34;http://www.goldencui.org/2014/12/06/%E7%AE%80%E6%98%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%A6%82%E8%BF%B0%EF%BC%88%E4%BA%8C%EF%BC%89/&#34;&gt;简明深度学习方法概述（二）&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.johndcook.com/blog/r_language_for_programmers/&#34;&gt;《R language for programmers》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Ｒ语言程序员私人定制版&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cheyun.com/content/news/4051&#34;&gt;《谷歌地图解密：大数据与机器学习的结合》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:谷歌地图解密&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.csdn.net/u012690204/article/details/41853731&#34;&gt;《空间数据挖掘常用方法》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:空间数据挖掘常用方法&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/c/word2vec-nlp-tutorial&#34;&gt;《Use Google&amp;rsquo;s Word2Vec for movie reviews》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Kaggle新比赛 ”When bag of words meets bags of popcorn“ aka ”边学边用word2vec和deep learning做NLP“ 里面全套教程教一步一步用python和gensim包的word2vec模型，并在实际比赛里面比调参数和清数据。 如果已装过gensim不要忘升级&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://pynlpir.readthedocs.org/en/latest/&#34;&gt;《PyNLPIR》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:PyNLPIR提供了NLPIR/ICTCLAS汉语分词的Python接口,此外&lt;a href=&#34;http://zhon.readthedocs.org/en/latest/&#34;&gt;Zhon&lt;/a&gt;提供了常用汉字常量，如CJK字符和偏旁，中文标点，拼音，和汉字正则表达式（如找到文本中的繁体字）&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.technologyreview.com/view/533496/why-neural-networks-look-set-to-thrash-the-best-human-go-players-for-the-first-time/&#34;&gt;《深度卷积神经网络下围棋》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:这文章说把最近模型识别上的突破应用到围棋软件上，打16万张职业棋谱训练模型识别功能。想法不错。训练后目前能做到不用计算，只看棋盘就给出下一步，大约10级棋力。但这篇文章太过乐观，说什么人类的最后一块堡垒马上就要跨掉了。话说得太早。不过，如果与别的软件结合应该还有潜力可挖。@万精油墨绿&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://mrtz.org/blog/the-nips-experiment/&#34;&gt;《NIPS审稿实验》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:UT Austin教授Eric Price关于今年NIPS审稿实验的详细分析,他表示，根据这次实验的结果，如果今年NIPS重新审稿的话，会有一半的论文被拒。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.kdnuggets.com/2014/12/top-kdnuggets-2014-analytics-big-data-science-stories.html&#34;&gt;《2014年最佳的大数据，数据科学文章》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:KDNuggets分别总结了2014年14个阅读最多以及分享最多的文章。我们从中可以看到多个主题——深度学习，数据科学家职业，教育和薪酬，学习数据科学的工具比如R和Python以及大众投票的最受欢迎的数据科学和数据挖掘语言&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.csdn.net/suipingsp/article/details/42101139&#34;&gt;《机器学习经典算法详解及Python实现&amp;ndash;线性回归（Linear Regression）算法》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Python实现线性回归,作者还有其他很棒的文章推荐可以看看&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://download.csdn.net/album/detail/1367/1/1&#34;&gt;《2014中国大数据技术大会33位核心专家演讲PDF》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：2014中国大数据技术大会33位核心专家演讲PDF下载&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1412.5335&#34;&gt;《使用RNN和Paragraph Vector做情感分析》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍：这是T. Mikolov &amp;amp; Y. Bengio最新论文Ensemble of Generative and Discriminative Techniques for Sentiment Analysis of Movie Reviews ，使用RNN和PV在情感分析效果不错，［项目代码］(&lt;a href=&#34;https://github.com/mesnilgr/iclr15)公布在github(目前是空的)。这意味着Paragraph&#34;&gt;https://github.com/mesnilgr/iclr15)公布在github(目前是空的)。这意味着Paragraph&lt;/a&gt; Vector终于揭开面纱了嘛。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://pan.baidu.com/s/1o6I9S18&#34;&gt;《NLPIR/ICTCLAS2015分词系统大会上的技术演讲 》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:NLPIR/ICTCLAS2015分词系统发布与用户交流大会上的演讲，请更多朋友检阅新版分词吧。  我们实验室同学的演讲包括：&lt;a href=&#34;http://pan.baidu.com/s/1hqotVVm&#34;&gt;孙梦姝-基于评论观点挖掘的商品搜索技术研究&lt;/a&gt; &lt;a href=&#34;http://pan.baidu.com/s/1pJ9KuZh&#34;&gt;李然-主题模型&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/code-poet/80ea3ec3c471&#34;&gt;《Machine Learning is Fun!》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Convex Neural Networks 解决维数灾难&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://dataunion.org/?p=5395&#34;&gt;《CNN的反向求导及练习》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:介绍CNN参数在使用bp算法时该怎么训练，毕竟CNN中有卷积层和下采样层，虽然和MLP的bp算法本质上相同，但形式上还是有些区别的，很显然在完成CNN反向传播前了解bp算法是必须的。此外作者也做了一个&lt;a href=&#34;http://www.cnblogs.com/tornadomeet/archive/2012/05/24/2515980.html&#34;&gt;资源集:机器学习，深度学习，视觉，数学等&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cloudflare/ahocorasick&#34;&gt;《正则表达式优化成Trie树 》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:如果要在一篇文章中匹配十万个关键词怎么办？&lt;a href=&#34;https://github.com/cloudflare/ahocorasick&#34;&gt;Aho-Corasick&lt;/a&gt; 算法利用添加了返回边的Trie树，能够在线性时间内完成匹配。 但如果匹配十万个正则表达式呢 ？ 这时候可以用到把多个正则优化成Trie树的方法，如日本人写的 &lt;a href=&#34;http://search.cpan.org/~dankogai/Regexp-Trie-0.02/&#34;&gt;Regexp::Trie&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://jmozah.github.io/links/&#34;&gt;《Deep learning Reading List》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:深度学习阅读清单&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://caffe.berkeleyvision.org/&#34;&gt;《Caffe》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Caffe是一个开源的深度学习框架，作者目前在google工作，作者主页&lt;a href=&#34;http://daggerfs.com/index.html&#34;&gt;Yangqing Jia (贾扬清)&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/BVLC/caffe/blob/master/models/bvlc_googlenet/readme.md&#34;&gt;《GoogLeNet深度学习模型的Caffe复现 》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:2014 ImageNet冠军GoogLeNet深度学习模型的Caffe复现模型,&lt;a href=&#34;http://arxiv.org/abs/1409.4842&#34;&gt;GoogleNet论文&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/jbarrow/LambdaNet&#34;&gt;《LambdaNet，Haskell实现的开源人工神经网络库 》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:LambdaNetLambdaNet是由Haskell实现的一个开源的人工神经网络库，它抽象了网络创建、训练并使用了高阶函数。该库还提供了一组预定义函数，用户可以采取多种方式组合这些函数来操作现实世界数据。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://wenku.baidu.com/course/view/49e8b8f67c1cfad6195fa705&#34;&gt;《百度余凯&amp;amp;张潼机器学习视频》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:如果你从事互联网搜索，在线广告，用户行为分析，图像识别，自然语言理解，或者生物信息学，智能机器人，金融预测，那么这门核心课程你必须深入了解。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://v.youku.com/v_show/id_XODQzNDM4MDg0.html&#34;&gt;《杨强在TEDxNanjing谈智能的起源》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:&amp;ldquo;人工智能研究分许多流派。其中之一以IBM为代表，认为只要有高性能计算就可得到智能，他们的‘深蓝’击败了世界象棋冠军；另一流派认为智能来自动物本能；还有个很强的流派认为只要找来专家，把他们的思维用逻辑一条条写下，放到计算机里就行……&amp;rdquo; 杨强在TEDxNanjing谈智能的起源&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.machinelearning.org/proceedings/icml2006/047_Connectionist_Tempor.pdf&#34;&gt;《深度RNN/LSTM用于结构化学习 0)序列标注Connectionist Temporal ClassificationICML06》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:1)机器翻译&lt;a href=&#34;http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf&#34;&gt;Sequence to Sequence NIPS14&lt;/a&gt; 2)成分句法&lt;a href=&#34;http://arxiv.org/pdf/1412.7449v1.pdf&#34;&gt;GRAMMAR AS FOREIGN LANGUAGE&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://techblog.youdao.com/?p=915&#34;&gt;《Deep Learning实战之word2vec》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:网易有道的三位工程师写的word2vec的解析文档，从基本的词向量/统计语言模型-&amp;gt;NNLM-&amp;gt;Log-Linear/Log-Bilinear-&amp;gt;层次化Log-Bilinear，到CBOW和Skip-gram模型，再到word2vec的各种tricks，公式推导与代码，基本上是网上关于word2vec资料的大合集，对word2vec感兴趣的朋友可以看看&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://mloss.org/software/&#34;&gt;《Machine learning open source software》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:机器学习开源软件,收录了各种机器学习的各种编程语言学术与商业的开源软件．与此类似的还有很多例如:&lt;a href=&#34;http://www.dmoz.org/Computers/Artificial_Intelligence/Machine_Learning/Software/&#34;&gt;DMOZ - Computers: Artificial Intelligence: Machine Learning: Software&lt;/a&gt;,　&lt;a href=&#34;http://www.csie.ntu.edu.tw/~cjlin/libsvm/&#34;&gt;LIBSVM &amp;ndash; A Library for Support Vector Machines&lt;/a&gt;,　&lt;a href=&#34;http://www.cs.waikato.ac.nz/ml/weka/&#34;&gt;Weka 3: Data Mining Software in Java&lt;/a&gt;,　&lt;a href=&#34;http://scikit-learn.org/stable/&#34;&gt;scikit-learn:Machine Learning in Python&lt;/a&gt;,　&lt;a href=&#34;www.nltk.org&#34;&gt;Natural Language Toolkit:NLTK&lt;/a&gt;,　&lt;a href=&#34;http://mallet.cs.umass.edu/&#34;&gt;MAchine Learning for LanguagE Toolkit&lt;/a&gt;,　&lt;a href=&#34;http://orange.biolab.si/&#34;&gt;Data Mining - Fruitful and Fun&lt;/a&gt;,　&lt;a href=&#34;http://opencv.willowgarage.com/wiki/&#34;&gt;Open Source Computer Vision Library&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.guokr.com/post/512037/&#34;&gt;《机器学习入门者学习指南》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:作者是计算机研二(写文章的时候，现在是2015年了应该快要毕业了)，专业方向自然语言处理．这是一点他的经验之谈．对于入门的朋友或许会有帮助&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/&#34;&gt;《A Tour of Machine Learning Algorithms》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:这是一篇关于机器学习算法分类的文章，非常好&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://ml.memect.com/download/2014.zip&#34;&gt;《2014年的《机器学习日报》大合集》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:机器学习日报里面推荐很多内容，在这里有一部分的优秀内容就是来自机器学习日报．&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.csdn.net/abcjennifer/article/details/42493493&#34;&gt;《 Image classification with deep learning常用模型》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:这是一篇关于图像分类在深度学习中的文章&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://research.microsoft.com/en-us/people/deng/&#34;&gt;《自动语音识别：深度学习方法》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:作者与Bengio的兄弟Samy 09年合编《自动语音识别：核方法》 3）李开复1989年《自动语音识别》专著，其博导、94年图灵奖得主Raj Reddy作序&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.csdn.net/heiyeshuwu/article/details/42554903&#34;&gt;《NLP中的中文分词技术》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 作者是360电商技术组成员,这是一篇NLP在中文分词中的应用&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/&#34;&gt;《Using convolutional neural nets to detect facial keypoints tutorial》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 使用deep learning的人脸关键点检测，此外还有一篇&lt;a href=&#34;https://www.kaggle.com/c/facial-keypoints-detection/details/deep-learning-tutorial&#34;&gt;AWS部署教程&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.amazon.cn/Advanced-Structured-Prediction-Nowozin-Sebastian/dp/0262028379&#34;&gt;《书籍推荐:Advanced Structured Prediction》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 由Sebastian Nowozin等人编纂MIT出版的新书《Advanced Structured Prediction》&lt;a href=&#34;http://t.cn/RZxipKG&#34;&gt;http://t.cn/RZxipKG&lt;/a&gt; ，汇集了结构化预测领域诸多牛文，涉及CV、NLP等领域，值得一读。网上公开的几章草稿:&lt;a href=&#34;http://www2.informatik.hu-berlin.de/~kloftmar/publications/strucBook.pdf&#34;&gt;一&lt;/a&gt;,&lt;a href=&#34;http://mlg.eng.cam.ac.uk/yutian/Publications/ChenGelfandWelling14-HerdingBookChapter.pdf&#34;&gt;二&lt;/a&gt;,&lt;a href=&#34;http://web.engr.oregonstate.edu/~sinisa/research/publications/StructPredictionChapter14.pdf&#34;&gt;三&lt;/a&gt;,&lt;a href=&#34;http://ttic.uchicago.edu/~meshi/papers/smoothCD_chapter.pdf&#34;&gt;四&lt;/a&gt;,&lt;a href=&#34;http://www.cs.ox.ac.uk/Stanislav.Zivny/homepage/publications/zwp14mit-draft.pdf&#34;&gt;五&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/pdf/1501.01571v1.pdf&#34;&gt;《An Introduction to Matrix Concentration Inequalities》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: Tropp把数学家用高深装逼的数学语言写的矩阵概率不等式用初等的方法写出来，是非常好的手册，领域内的paper各种证明都在用里面的结果。虽说是初等的，但还是非常的难&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://agenda.weforum.org/2014/12/the-free-big-data-sources-you-should-know/&#34;&gt;《The free big data sources you should know》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 不容错过的免费大数据集，有些已经是耳熟能详，有些可能还是第一次听说，内容跨越文本、数据、多媒体等，让他们伴你开始数据科学之旅吧，具体包括：Data.gov、US Census Bureau、European Union Open Data Portal、Data.gov.uk等&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://yyue.blogspot.com/2015/01/a-brief-overview-of-deep-learning.html&#34;&gt;《A Brief Overview of Deep Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 谷歌科学家、Hinton亲传弟子Ilya Sutskever的深度学习综述及实际建议&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://nikhilbuduma.com/2015/01/11/a-deep-dive-into-recurrent-neural-networks/&#34;&gt;《A Deep Dive into Recurrent Neural Nets》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 非常好的讨论递归神经网络的文章，覆盖了RNN的概念、原理、训练及优化等各个方面内容，强烈推荐！本文作者Nikhil Buduma还有一篇&lt;a href=&#34;http://nikhilbuduma.com/2014/12/29/deep-learning-in-a-nutshell/&#34;&gt;Deep Learning in a Nutshell&lt;/a&gt;值得推荐&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://qianjiye.de/2014/11/machine-learning-resources/&#34;&gt;《机器学习：学习资源》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:里面融合了很多的资源，例如竞赛，在线课程，demo，数据整合等。有分类&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.otexts.org/book/sfml&#34;&gt;《Statistical foundations of machine learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:《机器学习的统计基础》在线版，该手册希望在理论与实践之间找到平衡点，各主要内容都伴有实际例子及数据，书中的例子程序都是用R语言编写的。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks&#34;&gt;《A Deep Learning Tutorial: From Perceptrons to Deep Networks》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:IVAN VASILEV写的深度学习导引：从浅层感知机到深度网络。高可读&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://futureoflife.org/static/data/documents/research_priorities.pdf&#34;&gt;《Research priorities for robust and beneficial artificial intelligence》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:鲁棒及有益的人工智能优先研究计划：一封公开信,目前已经有Stuart Russell, Tom Dietterich, Eric Horvitz, Yann LeCun, Peter Norvig, Tom Mitchell, Geoffrey Hinton, Elon Musk等人签署&lt;a href=&#34;http://futureoflife.org/misc/open_letter&#34;&gt;The Future of Life Institute (FLI)&lt;/a&gt;.这封信的背景是最近霍金和Elon Musk提醒人们注意AI的潜在威胁。公开信的内容是AI科学家们站在造福社会的角度，展望人工智能的未来发展方向，提出开发AI系统的Verification，Validity, Security, Control四点要求，以及需要注意的社会问题。毕竟当前AI在经济领域，法律，以及道德领域相关研究较少。其实还有一部美剧&lt;a href=&#34;http://tv.sohu.com/20120925/n353925789.shtml&#34;&gt;《疑犯追踪》&lt;/a&gt;,介绍了AI的演进从一开始的自我学习，过滤，图像识别，语音识别等判断危险，到第四季的时候出现了机器通过学习成长之后想控制世界的状态。说到这里推荐收看。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://metacademy.org/&#34;&gt;《metacademy》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:里面根据词条提供了许多资源，还有相关知识结构，路线图，用时长短等。号称是”机器学习“搜索引擎&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://research.facebook.com/blog/879898285375829/fair-open-sources-deep-learning-modules-for-torch/&#34;&gt;《FAIR open sources deep-learning modules for Torch》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Facebook人工智能研究院（FAIR）开源了一系列软件库，以帮助开发者建立更大、更快的深度学习模型。开放的软件库在 Facebook 被称作模块。用它们替代机器学习领域常用的开发环境 Torch 中的默认模块，可以在更短的时间内训练更大规模的神经网络模型。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cnblogs.com/ello/archive/2012/04/28/2475419.html&#34;&gt;《浅析人脸检测之Haar分类器方法》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:本文虽然是写于2012年，但是这篇文章完全是作者的经验之作。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.ituring.com.cn/article/55994&#34;&gt;《如何成为一位数据科学家》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:本文是对《机器学习实战》作者Peter Harrington做的一个访谈。包含了书中部分的疑问解答和一点个人学习建议&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.metacademy.org/roadmaps/rgrosse/deep_learning&#34;&gt;《Deep learning from the bottom up》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:非常好的深度学习概述，对几种流行的深度学习模型都进行了介绍和讨论&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://onepager.togaware.com/TextMiningO.pdf&#34;&gt;《Hands-On Data Science with R Text Mining》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:主要是讲述了利用R语言进行数据挖掘&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://colah.github.io/posts/2014-07-Understanding-Convolutions/&#34;&gt;《Understanding Convolutions》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:帮你理解卷积神经网络，讲解很清晰，此外还有两篇&lt;a href=&#34;http://colah.github.io/posts/2014-07-Conv-Nets-Modular/&#34;&gt;Conv Nets: A Modular Perspective&lt;/a&gt;，&lt;a href=&#34;http://colah.github.io/posts/2014-12-Groups-Convolution/&#34;&gt;Groups &amp;amp; Group Convolutions&lt;/a&gt;. 作者的其他的关于神经网络文章也很棒&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.iro.umontreal.ca/~pift6266/H10/notes/deepintro.html#introduction-to-deep-learning-algorithms&#34;&gt;《Introduction to Deep Learning Algorithms》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Deep Learning算法介绍，里面介绍了06年3篇让deep learning崛起的论文&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.iro.umontreal.ca/~bengioy/papers/ftml_book.pdf&#34;&gt;《Learning Deep Architectures for AI》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:一本学习人工智能的书籍，作者是Yoshua Bengio，相关&lt;a href=&#34;http://www.infoq.com/cn/articles/ask-yoshua-bengio&#34;&gt;国内报道&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cs.toronto.edu/~hinton/&#34;&gt;《Geoffrey E. Hinton个人主页》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Geoffrey Hinton是Deep Learning的大牛，他的主页放了一些介绍性文章和课件值得学习&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://omega.albany.edu:8008/JaynesBook.html&#34;&gt;《PROBABILITY THEORY: THE LOGIC OF SCIENCE》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:概率论：数理逻辑书籍&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/h2oai/h2o&#34;&gt;《H2O》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:一个用来快速的统计，机器学习并且对于数据量大的数学库&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.iclr.cc/doku.php?id=iclr2015:main&#34;&gt;《ICLR 2015会议的arXiv稿件合集》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:在这里你可以看到最近深度学习有什么新动向。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www-nlp.stanford.edu/IR-book/&#34;&gt;《Introduction to Information Retrieval》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:此书在信息检索领域家喻户晓， 除提供该书的免费电子版外，还提供一个&lt;a href=&#34;http://www-nlp.stanford.edu/IR-book/information-retrieval.html&#34;&gt;IR资源列表&lt;/a&gt; ，收录了信息检索、网络信息检索、搜索引擎实现等方面相关的图书、研究中心、相关课程、子领域、会议、期刊等等，堪称全集，值得收藏&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://yosinski.com/mlss12/MLSS-2012-Amari-Information-Geometry/&#34;&gt;《Information Geometry and its Applications to Machine Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:信息几何学及其在机器学习中的应用&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://computationallegalstudies.com/2015/01/legal-analytics-introduction-course-professors-daniel-martin-katz-michael-j-bommarito/&#34;&gt;《Legal Analytics – Introduction to the Course》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:课程《法律分析》介绍幻灯片。用机器学习解决法律相关分析和预测问题，相关的法律应用包括预测编码、早期案例评估、案件整体情况的预测，定价和工作人员预测，司法行为预测等。法律领域大家可能都比较陌生，不妨了解下。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/yanxionglu/text_pdf&#34;&gt;《文本上的算法》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 文中提到了最优，模型，最大熵等等理论，此外还有应用篇。推荐系统可以说是一本不错的阅读稿，关于模型还推荐一篇&lt;a href=&#34;http://blog.sina.com.cn/s/blog_6742eecd0100iqcv.html&#34;&gt;Generative Model 与 Discriminative Model&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/karpathy/neuraltalk&#34;&gt;《NeuralTalk》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: NeuralTalk is a Python+numpy project for learning Multimodal Recurrent Neural Networks that describe images with sentences.NeuralTalk是一个Python的从图像生成自然语言描述的工具。它实现了Google (Vinyals等，卷积神经网络CNN + 长短期记忆LSTM) 和斯坦福 (Karpathy and Fei-Fei， CNN + 递归神经网络RNN)的算法。NeuralTalk自带了一个训练好的动物模型，你可以拿狮子大象的照片来试试看&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.paypal-engineering.com/2015/01/12/deep-learning-on-hadoop-2-0-2/&#34;&gt;《Deep Learning on Hadoop 2.0》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:本文主要介绍了在Hadoop2.0上使用深度学习,文章来自paypal&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1206.5533&#34;&gt;《Practical recommendations for gradient-based training of deep architectures》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:用基于梯度下降的方法训练深度框架的实践推荐指导,作者是&lt;a href=&#34;http://www.iro.umontreal.ca/~bengioy/yoshua_en/research.html&#34;&gt;Yoshua Bengio&lt;/a&gt; .感谢@xuewei4d 推荐&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://machinelearningmastery.com/machine-learning-statistical-causal-methods/&#34;&gt;《Machine Learning With Statistical And Causal Methods》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 用统计和因果方法做机器学习（视频报告）&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLD0F06AA0D2E8FFBA&#34;&gt;《Machine Learning Course 180’》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 一个讲机器学习的Youtube视频教程。160集。系统程度跟书可比拟。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cnblogs.com/LeftNotEasy/archive/2010/12/05/mathmatic_in_machine_learning_1_regression_and_gradient_descent.html&#34;&gt;《回归(regression)、梯度下降(gradient descent)》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 机器学习中的数学，作者的研究方向是机器学习，并行计算如果你还想了解一点其他的可以看看他&lt;a href=&#34;http://www.cnblogs.com/LeftNotEasy/archive/2011/05/02/recommended-blogspots.html&#34;&gt;博客&lt;/a&gt;的其他文章&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://tech.meituan.com/mt-recommend-practice.html&#34;&gt;《美团推荐算法实践》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 美团推荐算法实践，从框架，应用，策略，查询等分析&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1412.1632&#34;&gt;《Deep Learning for Answer Sentence Selection》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 深度学习用于问答系统答案句的选取&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.iro.umontreal.ca/~lisa/pointeurs/WWW2014.pdf&#34;&gt;《Learning Semantic Representations Using Convolutional Neural Networks for Web Search 》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: CNN用于WEB搜索，深度学习在文本计算中的应用&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/caesar0301/awesome-public-datasets&#34;&gt;《Awesome Public Datasets》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: Awesome系列中的公开数据集&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.academics.io/&#34;&gt;《Search Engine &amp;amp; Community》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 一个学术搜索引擎&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://honnibal.github.io/spaCy/&#34;&gt;《spaCy》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 用Python和Cython写的工业级自然语言处理库，号称是速度最快的NLP库，快的原因一是用Cython写的，二是用了个很巧妙的hash技术，加速系统的瓶颈，NLP中稀松特征的存取&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://fr.slideshare.net/MrChrisJohnson/collaborative-filtering-with-spark&#34;&gt;《Collaborative Filtering with Spark》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: &lt;a href=&#34;http://www.fields.utoronto.ca/video-archive/event/323/2014&#34;&gt;Fields&lt;/a&gt;是个数学研究中心,上面的这份ppt是来自Fields举办的活动中Russ Salakhutdinov带来的《大规模机器学习》分享&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.7300days.com/index.php/stds/topic/list/id/27/name/Topic%20modeling&#34;&gt;《Topic modeling 的经典论文》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: Topic modeling 的经典论文,标注了关键点&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1412.6564&#34;&gt;《Move Evaluation in Go Using Deep Convolutional Neural Networks》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 多伦多大学与Google合作的新论文，深度学习也可以用来下围棋，据说能达到六段水平&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://ztl2004.github.io/MachineLearningWeekly/issue2.html&#34;&gt;《机器学习周刊第二期》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 新闻，paper,课程，book，system,CES,Roboot，此外还推荐一个&lt;a href=&#34;http://blog.newitfarmer.com/ai/deep-learning/15302/repost-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E4%B8%8E%E7%BB%BC%E8%BF%B0%E8%B5%84%E6%96%99&#34;&gt;深度学习入门与综述资料&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.bigdata-madesimple.com/learning-more-like-a-human-18-free-ebooks-on-machine-learning/&#34;&gt;《Learning more like a human: 18 free eBooks on Machine Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 18 free eBooks on Machine Learning&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.hangli-hl.com/&#34;&gt;《Recommend :Hang Li Home》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Chief scientist of Noah&amp;rsquo;s Ark Lab of Huawei Technologies.He worked at the Research Laboratories of NEC Corporation during 1990 and 2001 and Microsoft Research Asia during 2001 and 2012.&lt;a href=&#34;http://www.hangli-hl.com/recent-publications.html&#34;&gt;Paper&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://memkite.com/deep-learning-bibliography/&#34;&gt;《DEEPLEARNING.UNIVERSITY – AN ANNOTATED DEEP LEARNING BIBLIOGRAPHY》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: DEEPLEARNING.UNIVERSITY的论文库已经收录了963篇经过分类的深度学习论文了，很多经典论文都已经收录&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=wTp3P2UnTfQ&amp;amp;hd=1&#34;&gt;《MLMU.cz - Radim Řehůřek - Word2vec &amp;amp; friends (7.1.2015)》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: Radim Řehůřek(Gensim开发者)在一次机器学习聚会上的报告，关于word2vec及其优化、应用和扩展，很实用.&lt;a href=&#34;http://pan.baidu.com/s/1c03wd24&#34;&gt;国内网盘&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://databricks.com/blog/2015/01/28/introducing-streaming-k-means-in-spark-1-2.html&#34;&gt;《Introducing streaming k-means in Spark 1.2》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:很多公司都用机器学习来解决问题，提高用户体验。那么怎么可以让机器学习更实时和有效呢？Spark MLlib 1.2里面的Streaming K-means，由斑马鱼脑神经研究的Jeremy Freeman脑神经科学家编写，最初是为了实时处理他们每半小时1TB的研究数据，现在发布给大家用了。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.hankcs.com/nlp/lda-java-introduction-and-implementation.html&#34;&gt;《LDA入门与Java实现》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 这是一篇面向工程师的LDA入门笔记，并且提供一份开箱即用Java实现。本文只记录基本概念与原理，并不涉及公式推导。文中的LDA实现核心部分采用了arbylon的LdaGibbsSampler并力所能及地注解了，在搜狗分类语料库上测试良好，开源在&lt;a href=&#34;https://github.com/hankcs/LDA4j&#34;&gt;GitHub&lt;/a&gt;上。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://aminer.org/&#34;&gt;《AMiner - Open Science Platform》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: AMiner是一个学术搜索引擎，从学术网络中挖掘深度知识、面向科技大数据的挖掘。收集近4000万作者信息、8000万论文信息、1亿多引用关系、链接近8百万知识点；支持专家搜索、机构排名、科研成果评价、会议排名。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.quora.com/What-are-some-interesting-Word2Vec-results&#34;&gt;《What are some interesting Word2Vec results?》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: Quora上的主题，讨论Word2Vec的有趣应用，Omer Levy提到了他在CoNLL2014最佳论文里的分析结果和新方法，Daniel Hammack给出了找特异词的小应用并提供了&lt;a href=&#34;https://github.com/dhammack/Word2VecExample&#34;&gt;(Python)代码&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.coursegraph.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B1%87%E6%80%BB&#34;&gt;《机器学习公开课汇总》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 机器学习公开课汇总,虽然里面的有些课程已经归档过了，但是还有个别的信息没有。感谢课程图谱的小编&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://linear.ups.edu/download.html&#34;&gt;《A First Course in Linear Algebra》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 【A First Course in Linear Algebra】Robert Beezer 有答案 有移动版、打印版 使用GNU自由文档协议 引用了杰弗逊1813年的信&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ShiqiYu/libfacedetection&#34;&gt;《libfacedetection》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:libfacedetection是深圳大学开源的一个人脸图像识别库。包含正面和多视角人脸检测两个算法.优点:速度快(OpenCV haar+adaboost的2-3倍), 准确度高 (FDDB非公开类评测排名第二），能估计人脸角度。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://dl.acm.org/citation.cfm?doid=2684822.2685310&#34;&gt;《Inverting a Steady-State》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:WSDM2015最佳论文 把马尔可夫链理论用在了图分析上面，比一般的propagation model更加深刻一些。通过全局的平稳分布去求解每个节点影响系数模型。假设合理（转移受到相邻的影响系数影响）。可以用来反求每个节点的影响系数&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://pan.baidu.com/s/1pJogO7x&#34;&gt;《机器学习入门书单》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:机器学习入门书籍，&lt;a href=&#34;http://www.hankcs.com/ml/machine-learning-entry-list.html&#34;&gt;具体介绍&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://v1v3kn.tumblr.com/post/47193952400/the-trouble-with-svms&#34;&gt;《The Trouble with SVMs》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 非常棒的强调特征选择对分类器重要性的文章。情感分类中，根据互信息对复杂高维特征降维再使用朴素贝叶斯分类器，取得了比SVM更理想的效果，训练和分类时间也大大降低——更重要的是，不必花大量时间在学习和优化SVM上——特征也一样no free lunch&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.stat.cmu.edu/~larry/Wasserman.pdf&#34;&gt;《Rise of the Machines》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:CMU的统计系和计算机系知名教授Larry Wasserman 在《机器崛起》,对比了统计和机器学习的差异&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://tech.meituan.com/mt-mlinaction-how-to-ml.html&#34;&gt;《实例详解机器学习如何解决问题》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:随着大数据时代的到来，机器学习成为解决问题的一种重要且关键的工具。不管是工业界还是学术界，机器学习都是一个炙手可热的方向，但是学术界和工业界对机器学习的研究各有侧重，学术界侧重于对机器学习理论的研究，工业界侧重于如何用机器学习来解决实际问题。这篇文章是美团的实际环境中的实战篇&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.gaussianprocess.org/gpml/&#34;&gt;《Gaussian Processes for Machine Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:面向机器学习的高斯过程，章节概要：回归、分类、协方差函数、模型选择与超参优化、高斯模型与其他模型关系、大数据集的逼近方法等,&lt;a href=&#34;http://vdisk.weibo.com/s/ayG13we2vfWuT&#34;&gt;微盘下载&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/&#34;&gt;《FuzzyWuzzy: Fuzzy String Matching in Python》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Python下的文本模糊匹配库，老库新推，可计算串间ratio(简单相似系数)、partial_ratio(局部相似系数)、token_sort_ratio(词排序相似系数)、token_set_ratio(词集合相似系数)等 &lt;a href=&#34;https://github.com/seatgeek/fuzzywuzzy&#34;&gt;github&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blocks.readthedocs.org/en/latest/&#34;&gt;《Blocks》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Blocks是基于Theano的神经网络搭建框架，集成相关函数、管道和算法，帮你更快地创建和管理NN模块.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://alex.smola.org/teaching/10-701-15/&#34;&gt;《Introduction to Machine Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:机器学习大神Alex Smola在CMU新一期的机器学习入门课程”Introduction to Machine Learning“近期刚刚开课，课程4K高清视频同步到Youtube上，目前刚刚更新到 2.4 Exponential Families,课程视频&lt;a href=&#34;https://www.youtube.com/playlist?list=PLZSO_6-bSqHTTV7w9u7grTXBHMH-mw3qn&#34;&gt;playlist&lt;/a&gt;, 感兴趣的同学可以关注，非常适合入门.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1502.01423&#34;&gt;《Collaborative Feature Learning from Social Media》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:用社交用户行为学习图片的协同特征，可更好地表达图片内容相似性。由于不依赖于人工标签(标注)，可用于大规模图片处理，难在用户行为数据的获取和清洗；利用社会化特征的思路值得借鉴.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.twitter.com/2015/introducing-practical-and-robust-anomaly-detection-in-a-time-series&#34;&gt;《Introducing practical and robust anomaly detection in a time series》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Twitter技术团队对前段时间开源的时间序列异常检测算法(S-H-ESD)R包的介绍，其中对异常的定义和分析很值得参考，文中也提到——异常是强针对性的，某个领域开发的异常检测在其他领域直接用可不行.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.destinationcrm.com/Articles/Web-Exclusives/Viewpoints/Empower-Your-Team-to-Deal-with-Data-Quality-Issues-101308.aspx&#34;&gt;《Empower Your Team to Deal with Data-Quality Issues》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:聚焦数据质量问题的应对，数据质量对各种规模企业的性能和效率都至关重要，文中总结出(不限于)22种典型数据质量问题显现的信号，以及典型的数据质量解决方案(清洗、去重、统一、匹配、权限清理等)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.52nlp.cn/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%85%A5%E9%97%A8%E4%B9%8B%E8%B5%84%E6%BA%90&#34;&gt;《中文分词入门之资源》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:中文分词入门之资源.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLnDbcXCpYZ8lCKExMs8k4PtIbani9ESX3&#34;&gt;《Deep Learning Summit, San Francisco, 2015》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:15年旧金山深度学习峰会视频集萃,&lt;a href=&#34;http://pan.baidu.com/s/1ntiLMcT&#34;&gt;国内云盘&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/&#34;&gt;《Introduction to Conditional Random Fields》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:很好的条件随机场(CRF)介绍文章,作者的学习笔记&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://cs.stanford.edu/~danqi/papers/emnlp2014.pdf&#34;&gt;《A Fast and Accurate Dependency Parser using Neural Networks》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 来自Stanford，用神经网络实现快速准确的依存关系解析器&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://timdettmers.wordpress.com/2014/08/14/which-gpu-for-deep-learning/&#34;&gt;《Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:做深度学习如何选择GPU的建议&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://new.livestream.com/accounts/10932136/events/3779068&#34;&gt;《Sparse Linear Models》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: Stanford的Trevor Hastie教授在H2O.ai Meet-Up上的报告，讲稀疏线性模型——面向“宽数据”(特征维数超过样本数)的线性模型,13年同&lt;a href=&#34;http://pan.baidu.com/s/1jimPw&#34;&gt;主题报告&lt;/a&gt; 、&lt;a href=&#34;http://pan.baidu.com/s/1o6wqW6u&#34;&gt;讲义&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/jbhuang0604/awesome-computer-vision&#34;&gt;《Awesome Computer Vision》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 分类整理的机器视觉相关资源列表，秉承Awesome系列风格，有质有量!作者的更新频率也很频繁&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.personal.ceu.hu/staff/Adam_Szeidl/&#34;&gt;《Adam Szeidl》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: social networks course&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://radar.oreilly.com/2015/01/building-and-deploying-large-scale-machine-learning-pipelines.html/&#34;&gt;《Building and deploying large-scale machine learning pipelines》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 大规模机器学习流程的构建与部署.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://download.csdn.net/detail/lswtzw/8469997&#34;&gt;《人脸识别开发包》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 人脸识别二次开发包，免费，可商用，有演示、范例、说明书.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://devblogs.nvidia.com/parallelforall/understanding-natural-language-deep-neural-networks-using-torch/&#34;&gt;《Understanding Natural Language with Deep Neural Networks Using Torch》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 采用Torch用深度学习网络理解NLP，来自Facebook 人工智能的文章.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/pdf/1503.00168.pdf&#34;&gt;《The NLP Engine: A Universal Turing Machine for NLP》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 来自CMU的Ed Hovy和Stanford的Jiwei Li一篇有意思的Arxiv文章,作者用Shannon Entropy来刻画NLP中各项任务的难度.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://staff.city.ac.uk/~sb317/papers/foundations_bm25_review.pdf&#34;&gt;《TThe Probabilistic Relevance Framework: BM25 and Beyond》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 信息检索排序模型BM25(Besting Matching)。1）从经典概率模型演变而来 2）捕捉了向量空间模型中三个影响索引项权重的因子：IDF逆文档频率；TF索引项频率；文档长度归一化。3）并且含有集成学习的思想：组合了BM11和BM15两个模型。4）作者是BM25的提出者和Okapi实现者Robertson.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.analyticsvidhya.com/blog/2015/03/introduction-auto-regression-moving-average-time-series/&#34;&gt;《Introduction to ARMA Time Series Models – simplified》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 自回归滑动平均(ARMA)时间序列的简单介绍，ARMA是研究时间序列的重要方法，由自回归模型（AR模型）与滑动平均模型（MA模型）为基础“混合”构成.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/pdf/1503.01838v1.pdf&#34;&gt;《Encoding Source Language with Convolutional Neural Network for Machine Translation》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 把来自target的attention signal加入source encoding CNN的输入，得到了比BBN的模型好的多neural network joint model&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1502.03815&#34;&gt;《Spices form the basis of food pairing in Indian cuisine》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 揭开印度菜的美味秘诀——通过对大量食谱原料关系的挖掘，发现印度菜美味的原因之一是其中的味道互相冲突，很有趣的文本挖掘研究&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.52nlp.cn/hmm%E7%9B%B8%E5%85%B3%E6%96%87%E7%AB%A0%E7%B4%A2%E5%BC%95&#34;&gt;《HMM相关文章索引》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: HMM相关文章,此外推荐&lt;a href=&#34;http://yanyiwu.com/work/2014/04/07/hmm-segment-xiangjie.html&#34;&gt;中文分词之HMM模型详解&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.ccs.neu.edu/home/ekanou/ISU535.09X2/Handouts/Review_Material/zipfslaw.pdf&#34;&gt;《Zipf&amp;rsquo;s and Heap&amp;rsquo;s law》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 1)词频与其降序排序的关系,最著名的是语言学家齐夫(Zipf,1902-1950)1949年提出的Zipf‘s law,即二者成反比关系. 曼德勃罗(Mandelbrot,1924- 2010)引入参数修正了对甚高频和甚低频词的刻画 2)Heaps&amp;rsquo; law: 词汇表与语料规模的平方根(这是一个参数,英语0.4-0.6)成正比&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.reddit.com/r/MachineLearning/comments/2xcyrl/i_am_j%C3%BCrgen_schmidhuber_ama/&#34;&gt;《I am Jürgen Schmidhuber, AMA》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: Jürgen Schmidhuber在Reddit上的AMA(Ask Me Anything)主题，有不少RNN和AI、ML的干货内容，关于开源&amp;amp;思想&amp;amp;方法&amp;amp;建议……耐心阅读，相信你也会受益匪浅.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://academictorrents.com/&#34;&gt;《学术种子网站：AcademicTorrents》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 成G上T的学术数据，HN近期热议话题,主题涉及机器学习、NLP、SNA等。下载最简单的方法，通过BT软件，RSS订阅各集合即可&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html&#34;&gt;《机器学习交互速查表》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: Scikit-Learn官网提供，在原有的Cheat Sheet基础上加上了Scikit-Learn相关文档的链接，方便浏览&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://timdettmers.wordpress.com/2015/03/09/deep-learning-hardware-guide/&#34;&gt;《A Full Hardware Guide to Deep Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 深度学习的全面硬件指南，从GPU到RAM、CPU、SSD、PCIe&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://hi.baidu.com/susongzhi/item/085983081b006311eafe38e7&#34;&gt;《行人检测(Pedestrian Detection)资源》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Pedestrian Detection paper &amp;amp; data&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1502.01241&#34;&gt;《A specialized face-processing network consistent with the representational geometry of monkey face patches》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 【神经科学碰撞人工智能】在脸部识别上你我都是专家，即使细微的差别也能辨认。研究已证明人类和灵长类动物在面部加工上不同于其他物种，人类使用梭状回面孔区（FFA）。Khaligh-Razavi等通过计算机模拟出人脸识别的FFA活动，堪称神经科学与人工智能的完美结合。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://vimeo.com/19569529&#34;&gt;《Neural Net in C++ Tutorial》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 神经网络C++教程,本文介绍了用可调节梯度下降和可调节动量法设计和编码经典BP神经网络，网络经过训练可以做出惊人和美妙的东西出来。此外作者博客的其他文章也很不错。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://deeplearning4j.org/neuralnetworktable.html&#34;&gt;《How to Choose a Neural Network》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:deeplearning4j官网提供的实际应用场景NN选择参考表，列举了一些典型问题建议使用的神经网络&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/yusugomori/DeepLearning&#34;&gt;《Deep Learning (Python, C/C++, Java, Scala, Go)》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:一个深度学习项目,提供了Python, C/C++, Java, Scala, Go多个版本的代码&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://deeplearning.net/tutorial/&#34;&gt;《Deep Learning Tutorials》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:深度学习教程,&lt;a href=&#34;https://github.com/lisa-lab/DeepLearningTutorials&#34;&gt;github&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.ccf.org.cn/resources/1190201776262/2015/03/12/15.pdf&#34;&gt;《自然语言处理的发展趋势——访卡内基梅隆大学爱德华·霍威教授》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:自然语言处理的发展趋势——访卡内基梅隆大学爱德华·霍威教授.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1503.03832&#34;&gt;《FaceNet: A Unified Embedding for Face Recognition and Clustering》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Google对Facebook DeepFace的有力回击—— FaceNet，在LFW(Labeled Faces in the Wild)上达到99.63%准确率(新纪录)，FaceNet embeddings可用于人脸识别、鉴别和聚类.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://databricks.com/blog/2015/01/21/random-forests-and-boosting-in-mllib.html&#34;&gt;《MLlib中的Random Forests和Boosting》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:本文来自Databricks公司网站的一篇博客文章，由Joseph Bradley和Manish Amde撰写，文章主要介绍了Random Forests和Gradient-Boosted Trees（GBTs）算法和他们在MLlib中的分布式实现，以及展示一些简单的例子并建议该从何处上手.&lt;a href=&#34;http://www.csdn.net/article/2015-03-11/2824178&#34;&gt;中文版&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://spn.cs.washington.edu/index.shtml&#34;&gt;《Sum-Product Networks(SPN) 》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:华盛顿大学Pedro Domingos团队的DNN，提供论文和实现代码.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://nlp.stanford.edu/software/nndep.shtml&#34;&gt;《Neural Network Dependency Parser》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:基于神经网络的自然语言依存关系解析器(已集成至Stanford CoreNLP)，特点是超快、准确，目前可处理中英文语料，基于&lt;a href=&#34;http://cs.stanford.edu/~danqi/papers/emnlp2014.pdf&#34;&gt;《A Fast and Accurate Dependency Parser Using Neural Networks》&lt;/a&gt; 思路实现.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.flickering.cn/nlp/2015/03/%E6%88%91%E4%BB%AC%E6%98%AF%E8%BF%99%E6%A0%B7%E7%90%86%E8%A7%A3%E8%AF%AD%E8%A8%80%E7%9A%84-3%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/&#34;&gt;《神经网络语言模型》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:本文根据神经网络的发展历程，详细讲解神经网络语言模型在各个阶段的形式，其中的模型包含NNLM[Bengio,2003]、Hierarchical NNLM[Bengio, 2005], Log-Bilinear[Hinton, 2007],SENNA等重要变形，总结的特别好.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.elg.uottawa.ca/~nat/Courses/csi5387_Winter2014/paper13.pdf&#34;&gt;《Classifying Spam Emails using Text and Readability Features》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:经典问题的新研究：利用文本和可读性特征分类垃圾邮件。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/alexandrebarachant/bci-challenge-ner-2015&#34;&gt;《BCI Challenge @ NER 2015》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:&lt;a href=&#34;https://www.kaggle.com/c/inria-bci-challenge&#34;&gt;Kaggle脑控计算机交互(BCI)竞赛&lt;/a&gt;优胜方案源码及文档，包括完整的数据处理流程，是学习Python数据处理和Kaggle经典参赛框架的绝佳实例&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.ipol.im/&#34;&gt;《IPOL Journal · Image Processing On Line》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:IPOL（在线图像处理）是图像处理和图像分析的研究期刊，每篇文章都包含一个算法及相应的代码、Demo和实验文档。文本和源码是经过了同行评审的。IPOL是开放的科学和可重复的研究期刊。我一直想做点类似的工作，拉近产品和技术之间的距离.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://eprint.iacr.org/2014/331&#34;&gt;《Machine learning classification over encrypted data》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:出自MIT，研究加密数据高效分类问题.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/purine/purine2&#34;&gt;《purine2》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:新加坡LV实验室的神经网络并行框架&lt;a href=&#34;http://arxiv.org/abs/1412.6249&#34;&gt;Purine: A bi-graph based deep learning framework&lt;/a&gt;,支持构建各种并行的架构，在多机多卡，同步更新参数的情况下基本达到线性加速。12块Titan 20小时可以完成Googlenet的训练。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://michal.io/machine-learning-resources/&#34;&gt;《Machine Learning Resources》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:这是一个机器学习资源库,虽然比较少.但蚊子再小也是肉.有突出部分.此外还有一个由&lt;a href=&#34;http://zhengrui.github.io/zerryland/ML-CV-Resource.html&#34;&gt;zheng Rui整理的机器学习资源&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cjdd3b/nicar2015/tree/master/machine-learning&#34;&gt;《Hands-on with machine learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Chase Davis在NICAR15上的主题报告材料，用Scikit-Learn做监督学习的入门例子.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cse.unsw.edu.au/~billw/nlpdict.html&#34;&gt;《The Natural Language Processing Dictionary》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:这是一本自然语言处理的词典,从1998年开始到目前积累了成千上万的专业词语解释,如果你是一位刚入门的朋友.可以借这本词典让自己成长更快.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1503.01331&#34;&gt;《PageRank Approach to Ranking National Football Teams》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:通过分析1930年至今的比赛数据，用PageRank计算世界杯参赛球队排行榜.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://cyclismo.org/tutorial/R/&#34;&gt;《R Tutorial》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:R语言教程,此外还推荐一个R语言教程&lt;a href=&#34;http://cran.r-project.org/doc/manuals/R-intro.html&#34;&gt;An Introduction to R&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/0803.0476&#34;&gt;《Fast unfolding of communities in large networks》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:经典老文，复杂网络社区发现的高效算法，Gephi中的&lt;a href=&#34;The Louvain method for community detection in large networks&#34;&gt;Community detection&lt;/a&gt;即基于此.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://numl.net/&#34;&gt;《NUML》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 一个面向 .net 的开源机器学习库,&lt;a href=&#34;https://github.com/sethjuarez/numl&#34;&gt;github地址&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://synaptic.juancazala.com/&#34;&gt;《synaptic.Js》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 支持node.js的JS神经网络库，可在客户端浏览器中运行，支持LSTM等 &lt;a href=&#34;https://github.com/cazala/synaptic&#34;&gt;github地址&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://tjo-en.hatenablog.com/entry/2015/03/20/191614&#34;&gt;《Machine learning for package users with R (1): Decision Tree》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 决策树&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.kdnuggets.com/2015/03/deep-learning-curse-dimensionality-autoencoders.html&#34;&gt;《Deep Learning, The Curse of Dimensionality, and Autoencoders》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:  讨论深度学习自动编码器如何有效应对维数灾难,&lt;a href=&#34;http://www.36dsj.com/archives/26223&#34;&gt;国内翻译&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cs.cmu.edu/~suvrit/teach/&#34;&gt;《Advanced Optimization and Randomized Methods》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: CMU的优化与随机方法课程，由A. Smola和S. Sra主讲，优化理论是机器学习的基石，值得深入学习 &lt;a href=&#34;http://pan.baidu.com/s/1c0cZtQC&#34;&gt;国内云(视频)&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://cs231n.stanford.edu/reports.html&#34;&gt;《CS231n: Convolutional Neural Networks for Visual Recognition》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: &amp;ldquo;面向视觉识别的CNN&amp;rdquo;课程设计报告集锦.近百篇，内容涉及图像识别应用的各个方面&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://databricks.com/blog/2015/03/25/topic-modeling-with-lda-mllib-meets-graphx.html&#34;&gt;《Topic modeling with LDA: MLlib meets GraphX》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:用Spark的MLlib+GraphX做大规模LDA主题抽取.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1502.05988&#34;&gt;《Deep Learning for Multi-label Classification》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 基于深度学习的多标签分类,用基于RBM的DBN解决多标签分类(特征)问题&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://deepmind.com/publications.html&#34;&gt;《Google DeepMind publications》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: DeepMind论文集锦&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://kaldi-asr.org/&#34;&gt;《kaldi》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 一个开源语音识别工具包,它目前托管在&lt;a href=&#34;http://sourceforge.net/projects/kaldi/&#34;&gt;sourceforge&lt;/a&gt;上面&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://datajournalismhandbook.org/&#34;&gt;《Data Journalism Handbook》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 免费电子书《数据新闻手册》, 国内有热心的朋友翻译了&lt;a href=&#34;http://datajournalismhandbook.org/chinese/index.html&#34;&gt;中文版&lt;/a&gt;,大家也可以&lt;a href=&#34;http://datajournalismhandbook.org/1.0/en/&#34;&gt;在线阅读&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://highlyscalable.wordpress.com/2015/03/10/data-mining-problems-in-retail/&#34;&gt;《Data Mining Problems in Retail》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 零售领域的数据挖掘文章.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://timdettmers.wordpress.com/2015/03/26/convolution-deep-learning/&#34;&gt;《Understanding Convolution in Deep Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 深度学习卷积概念详解,深入浅出.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://pandas.pydata.org/&#34;&gt;《pandas: powerful Python data analysis toolkit》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 非常强大的Python的数据分析工具包.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://breakthroughanalysis.com/2015/03/23/text-analytics-2015/&#34;&gt;《Text Analytics 2015》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 2015文本分析(商业)应用综述.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.slideshare.net/VincenzoLomonaco/deep-learning-libraries-and-rst-experiments-with-theano&#34;&gt;《Deep Learning libraries and ﬁrst experiments with Theano》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 深度学习框架、库调研及Theano的初步测试体会报告.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.deeplearningbook.org/&#34;&gt;《DEEP learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:  MIT的Yoshua Bengio, Ian Goodfellow, Aaron Courville著等人讲深度学习的新书，还未定稿，线上提供Draft chapters收集反馈，超赞！强烈推荐.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hickeroar/simplebayes&#34;&gt;《simplebayes》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: Python下开源可持久化朴素贝叶斯分类库.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://paracel.io/&#34;&gt;《Paracel》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Paracel is a distributed computational framework designed for machine learning problems, graph algorithms and scientific computing in C++.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://hanlp.linrunsoft.com/&#34;&gt;《HanLP:Han Language processing》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 开源汉语言处理包.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.rubylab.io/2015/03/18/simple-neural-network-implenentation-in-ruby/&#34;&gt;《Simple Neural Network implementation in Ruby》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 使用Ruby实现简单的神经网络例子.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://karpathy.github.io/neuralnets/&#34;&gt;《Hacker&amp;rsquo;s guide to Neural Networks》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:神经网络黑客入门.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://datasciencemasters.org/&#34;&gt;《The Open-Source Data Science Masters》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:好多数据科学家名人推荐,还有资料.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1502.01710&#34;&gt;《Text Understanding from Scratch》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:实现项目已经开源在github上面&lt;a href=&#34;https://github.com/zhangxiangxiao/Crepe&#34;&gt;Crepe&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://levyomer.files.wordpress.com/2015/03/improving-distributional-similarity-tacl-2015.pdf&#34;&gt;《 Improving Distributional Similarity with Lessons Learned from Word Embeddings》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:作者发现，经过调参，传统的方法也能和word2vec取得差不多的效果。另外，无论作者怎么试，GloVe都比不过word2vec.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://cs224d.stanford.edu/index.html&#34;&gt;《CS224d: Deep Learning for Natural Language Processing》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Stanford深度学习与自然语言处理课程,Richard Socher主讲.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://courses.washington.edu/css490/2012.Winter/lecture_slides/02_math_essentials.pdf&#34;&gt;《Math Essentials in Machine Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:机器学习中的重要数学概念.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1503.00007&#34;&gt;《Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:用于改进语义表示的树型LSTM递归神经网络,句子级相关性判断和情感分类效果很好.&lt;a href=&#34;https://github.com/stanfordnlp/treelstm&#34;&gt;实现代码&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.stat.cmu.edu/~larry/=sml/&#34;&gt;《Statistical Machine Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:卡耐基梅隆Ryan Tibshirani和Larry Wasserman开设的机器学习课程，先修课程为机器学习(10-715)和中级统计学(36-705)，聚焦统计理论和方法在机器学习领域应用.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://am207.org/&#34;&gt;《AM207: Monte Carlo Methods, Stochastic Optimization》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:《哈佛大学蒙特卡洛方法与随机优化课程》是哈佛应用数学研究生课程，由V Kaynig-Fittkau、P Protopapas主讲，Python程序示例，对贝叶斯推理感兴趣的朋友一定要看看，提供授&lt;a href=&#34;http://nbviewer.ipython.org/github/AM207/2015/tree/master/Lectures/&#34;&gt;课视频及课上IPN讲义&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://spark-summit.org/wp-content/uploads/2015/03/SSE15-40-Danford.pdf&#34;&gt;《生物医学的SPARK大数据应用》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:生物医学的SPARK大数据应用.并且伯克利开源了他们的big data genomics系统&lt;a href=&#34;https://github.com/bigdatagenomics/adam&#34;&gt;ADAM&lt;/a&gt;，其他的内容可以关注一下&lt;a href=&#34;http://spark-summit.org/&#34;&gt;官方主页&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://aclanthology.info/&#34;&gt;《ACL Anthology》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:对自然语言处理技术或者机器翻译技术感兴趣的亲们，请在提出自己牛逼到无以伦比的idea（自动归纳翻译规律、自动理解语境、自动识别语义等等）之前，请通过谷歌学术简单搜一下，如果谷歌不可用，这个网址有这个领域几大顶会的论文列表,切不可断章取义,胡乱假设.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.uni-weimar.de/medien/webis/publications/papers/stein_2015b.pdf&#34;&gt;《Twitter Sentiment Detection via Ensemble Classification Using Averaged Confidence Scores》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:论文+代码:基于集成方法的Twitter情感分类,&lt;a href=&#34;https://github.com/webis-de/ECIR-2015-and-SEMEVAL-2015&#34;&gt;实现代码&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://ciml.chalearn.org/schedule&#34;&gt;《NIPS 2014 CIML workshop》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:NIPS CiML 2014的PPT,NIPS是神经信息处理系统进展大会的英文简称.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://cs231n.stanford.edu/reports.html&#34;&gt;《CS231n: Convolutional Neural Networks for Visual Recognition》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:斯坦福的深度学习课程的Projects 每个人都要写一个论文级别的报告 里面有一些很有意思的应用 大家可以看看 .&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.sumsar.net/blog/2015/03/a-speed-comparison-between-flexible-linear-regression-alternatives-in-r/&#34;&gt;《A Speed Comparison Between Flexible Linear Regression Alternatives in R》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:R语言线性回归多方案速度比较具体方案包括lm()、nls()、glm()、bayesglm()、nls()、mle2()、optim()和Stan’s optimizing()等.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.allthingsdistributed.com/2015/04/machine-learning.html&#34;&gt;《Back-to-Basics Weekend Reading - Machine Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:文中提到的三篇论文（机器学习那些事、无监督聚类综述、监督分类综述）都很经典，Domnigos的机器学习课也很精彩&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1504.00641&#34;&gt;《A Probabilistic Theory of Deep Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:莱斯大学（Rice University）的深度学习的概率理论.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.gregreda.com/2015/03/30/beer-review-markov-chains/&#34;&gt;《Nonsensical beer reviews via Markov chains》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:基于马尔可夫链自动生成啤酒评论的开源Twitter机器人,&lt;a href=&#34;https://github.com/gjreda/beer-snob-says&#34;&gt;github地址&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://nlp.stanford.edu/courses/NAACL2013/&#34;&gt;《Deep Learning for Natural Language Processing (without Magic)》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:视频+讲义:深度学习用于自然语言处理教程(NAACL13).&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=U4IYsLgNgoY&amp;amp;hd=1&#34;&gt;《Introduction to Data Analysis using Machine Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:用机器学习做数据分析,David Taylor最近在McGill University研讨会上的报告，还提供了一系列讲机器学习方法的ipn，很有价值 &lt;a href=&#34;https://github.com/Prooffreader/intro_machine_learning&#34;&gt;GitHub&lt;/a&gt;.&lt;a href=&#34;http://pan.baidu.com/s/1mgtE9te&#34;&gt;国内&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1503.08909&#34;&gt;《Beyond Short Snippets: Deep Networks for Video Classification》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:基于CNN+LSTM的视频分类,&lt;a href=&#34;http://pan.baidu.com/s/1c0cZS9E&#34;&gt;google演示&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.quora.com/How-does-Quora-use-machine-learning-in-2015/answer/Xavier-Amatriain&#34;&gt;《How does Quora use machine learning in 2015?》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Quora怎么用机器学习.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.amazon.com/cn/blogs/aws/amazon-machine-learning-make-data-driven-decisions-at-scale/&#34;&gt;《Amazon Machine Learning – Make Data-Driven Decisions at Scale》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:亚马逊在机器学习上面的一些应用,&lt;a href=&#34;https://github.com/awslabs/machine-learning-samples&#34;&gt;代码示例&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ogrisel/parallel_ml_tutorial&#34;&gt;《Parallel Machine Learning with scikit-learn and IPython》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:并行机器学习指南(基于scikit-learn和IPython).&lt;a href=&#34;http://nbviewer.ipython.org/github/ogrisel/parallel_ml_tutorial/tree/master/notebooks/&#34;&gt;notebook&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.kaggle.com/2015/04/08/new-video-series-introduction-to-machine-learning-with-scikit-learn/&#34;&gt;《Intro to machine learning with scikit-learn》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:DataSchool的机器学习基本概念教学.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hughperkins/DeepCL&#34;&gt;《DeepCLn》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:一个基于OpenGL实现的卷积神经网络，支持Linux及Windows系.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.mapr.com/blog/inside-look-at-components-of-recommendation-engine&#34;&gt;《An Inside Look at the Components of a Recommendation Engine》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:基于Mahout和Elasticsearch的推荐系统.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.ssc.upenn.edu/~fdiebold/Teaching221/econ221.html&#34;&gt;《Forecasting in Economics, Business, Finance and Beyond》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Francis X. Diebold的《(经济|商业|金融等领域)预测方法.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.ssc.upenn.edu/~fdiebold/Teaching706/econ706Penn.html&#34;&gt;《Time Series Econometrics - A Concise Course》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Francis X. Diebold的《时序计量经济学》.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://fotiad.is/blog/sentiment-analysis-comparison/&#34;&gt;《A comparison of open source tools for sentiment analysis》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:基于Yelp数据集的开源&lt;a href=&#34;https://github.com/sfotiadis/yenlp&#34;&gt;情感分析工具&lt;/a&gt;比较,评测覆盖Naive Bayes、SentiWordNet、CoreNLP等 .&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://vdisk.weibo.com/s/ayG13we2u_sAZ&#34;&gt;《Pattern Recognition And Machine Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:国内Pattern Recognition And Machine Learning读书会资源汇总,&lt;a href=&#34;http://vdisk.weibo.com/u/1841149974&#34;&gt;各章pdf讲稿&lt;/a&gt;,&lt;a href=&#34;http://www.cnblogs.com/Nietzsche/&#34;&gt;博客&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://highlyscalable.wordpress.com/2012/05/01/probabilistic-structures-web-analytics-data-mining/&#34;&gt;《Probabilistic Data Structures for Web Analytics and Data Mining 》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:用于Web分析和数据挖掘的概率数据结构.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blindmotion.github.io/2015/04/11/ml-in-navigation/&#34;&gt;《Machine learning in navigation devices: detect maneuvers using accelerometer and gyroscope》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:机器学习在导航上面的应用.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/user/Taylorns34/videos&#34;&gt;《Neural Networks Demystified 》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Neural Networks Demystified系列视频，Stephen Welch制作，纯手绘风格，浅显易懂,&lt;a href=&#34;http://pan.baidu.com/s/1i3AFURj&#34;&gt;国内云&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.datacamp.com/swirl-r-tutorial&#34;&gt;《swirl + DataCamp 》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:{swirl}数据训练营:R&amp;amp;数据科学在线交互教程.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.terminal.com/recurrent-neural-networks-deep-net-optimization-lstm/&#34;&gt;《Learning to Read with Recurrent Neural Networks 》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:关于深度学习和RNN的讨论 &lt;a href=&#34;http://arxiv.org/abs/1409.3215&#34;&gt;Sequence to Sequence Learning with Neural Networks&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://wanghaitao8118.blog.163.com/blog/static/13986977220153811210319/&#34;&gt;《深度强化学习（Deep Reinforcement Learning）的资源》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Deep Reinforcement Learning.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/jakevdp/sklearn_pycon2015&#34;&gt;《Machine Learning with Scikit-Learn》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:(PyCon2015)Scikit-Learn机器学习教程,&lt;a href=&#34;https://github.com/ogrisel/parallel_ml_tutorial&#34;&gt;Parallel Machine Learning with scikit-learn and IPython&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cs.cmu.edu/~ymiao/pdnntk.html&#34;&gt;《PDNN》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:PDNN: A Python Toolkit for Deep Learning.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://alex.smola.org/teaching/10-701-15/index.html&#34;&gt;《Introduction to Machine Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:15年春季学期CMU的机器学习课程，由Alex Smola主讲，提供讲义及授课视频，很不错.&lt;a href=&#34;http://pan.baidu.com/s/1pJxBePX&#34;&gt;国内镜像&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.st.ewi.tudelft.nl/~hauff/TI2736-B.html&#34;&gt;《Big Data Processing》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:大数据处理课.内容覆盖流处理、MapReduce、图算法等.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.hakkalabs.co/articles/spark-mllib-making-practical-machine-learning-easy-and-scalable&#34;&gt;《Spark MLlib: Making Practical Machine Learning Easy and Scalable》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:用Spark MLlib实现易用可扩展的机器学习,&lt;a href=&#34;http://pan.baidu.com/s/1gdxSOZh&#34;&gt;国内镜像&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://mrkulk.github.io/www_cvpr15/&#34;&gt;《Picture: A Probabilistic Programming Language for Scene Perception》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:以往上千行代码概率编程(语言)实现只需50行.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://zevross.com/blog/2014/08/04/beautiful-plotting-in-r-a-ggplot2-cheatsheet-3/&#34;&gt;《Beautiful plotting in R: A ggplot2 cheatsheet》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:ggplot2速查小册子,&lt;a href=&#34;http://www.ling.upenn.edu/~joseff/avml2012/&#34;&gt;另外一个&lt;/a&gt;,此外还推荐&lt;a href=&#34;http://zevross.com/blog/2015/01/13/a-new-data-processing-workflow-for-r-dplyr-magrittr-tidyr-ggplot2/&#34;&gt;《A new data processing workflow for R: dplyr, magrittr, tidyr, ggplot2》&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://emnlp2014.org/papers/pdf/EMNLP2014148.pdf&#34;&gt;《Using Structured Events to Predict Stock Price Movement: An Empirical Investigation》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:用结构化模型来预测实时股票行情.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://ijcai-15.org/index.php/accepted-papers&#34;&gt;《International Joint Conference on Artificial Intelligence Accepted paper》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:&lt;a href=&#34;http://ijcai.org/&#34;&gt;国际人工智能联合会议&lt;/a&gt;录取论文列表,大部分论文可使用Google找到.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://petewarden.com/2015/04/20/why-gemm-is-at-the-heart-of-deep-learning/&#34;&gt;《Why GEMM is at the heart of deep learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:一般矩阵乘法(GEMM)对深度学习的重要性.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dmlc&#34;&gt;《Distributed (Deep) Machine Learning Common》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:A Community of awesome Distributed Machine Learning C++ projects.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://webdocs.cs.ualberta.ca/~sutton/book/the-book.html&#34;&gt;《Reinforcement Learning: An Introduction》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:免费电子书&amp;lt;强化学习介绍&amp;gt;,&lt;a href=&#34;http://pan.baidu.com/s/1jkaMq&#34;&gt;第一版(1998)&lt;/a&gt;,&lt;a href=&#34;http://pan.baidu.com/s/1dDnNEnR&#34;&gt;第二版(2015草稿)&lt;/a&gt;,相关课程&lt;a href=&#34;http://incompleteideas.net/rlai.cs.ualberta.ca/RLAI/RLAIcourse/2010.html&#34;&gt;资料&lt;/a&gt;,&lt;a href=&#34;http://www.inf.ed.ac.uk/teaching/courses/rl/&#34;&gt;Reinforcement Learning&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blogs.msdn.com/b/microsoft_press/archive/2015/04/15/free-ebook-microsoft-azure-essentials-azure-machine-learning.aspx&#34;&gt;《Free ebook: Microsoft Azure Essentials: Azure Machine Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:免费书:Azure ML使用精要.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks&#34;&gt;《A Deep Learning Tutorial: From Perceptrons to Deep Networks》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:A Deep Learning Tutorial: From Perceptrons to Deep Networks.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471&#34;&gt;《Machine Learning is Fun! - The world’s easiest introduction to Machine Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:有趣的机器学习：最简明入门指南,&lt;a href=&#34;http://blog.jobbole.com/67616/&#34;&gt;中文版&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;yyue.blogspot.com/2015/01/a-brief-overview-of-deep-learning.html&#34;&gt;《A Brief Overview of Deep Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:深度学习简明介绍,&lt;a href=&#34;http://xhrwang.me/2015/01/16/a-brief-overview-of-deep-learning.html&#34;&gt;中文版&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dmlc/wormhole&#34;&gt;《Wormhole》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Portable, scalable and reliable distributed machine learning.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/soumith/convnet-benchmarks&#34;&gt;《convnet-benchmarks》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:CNN开源实现横向评测,参评框架包括Caffe 、Torch-7、CuDNN 、cudaconvnet2 、fbfft、Nervana Systems等，NervanaSys表现突出.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://islpc21.is.cs.cmu.edu:3000/lti_catalogue&#34;&gt;《This catalogue lists resources developed by faculty and students of the Language Technologies Institute.》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:卡耐基梅隆大学计算机学院语言技术系的资源大全,包括大量的NLP开源软件工具包，基础数据集，论文集，数据挖掘教程，机器学习资源.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/mayank93/Twitter-Sentiment-Analysis&#34;&gt;《Sentiment Analysis on Twitter》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Twitter情感分析工具SentiTweet,&lt;a href=&#34;http://pan.baidu.com/s/1i3kXPlj&#34;&gt;视频+讲义&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://machinelearning.wustl.edu/mlpapers/venues&#34;&gt;《Machine Learning Repository @ Wash U》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:华盛顿大学的Machine Learning Paper Repository.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/soulmachine/machine-learning-cheat-sheet&#34;&gt;《Machine learning cheat sheet》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:机器学习速查表.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://spark-summit.org/east&#34;&gt;《Spark summit east 2015 agenda》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:最新的Spark summit会议资料.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://spark-summit.org/east&#34;&gt;《Spark summit east 2015 agenda》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:最新的Spark summit会议资料.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://pan.baidu.com/s/1eQkybJG&#34;&gt;《Learning Spark》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Ebook Learning Spark.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://pan.baidu.com/s/1jGot9qe&#34;&gt;《Advanced Analytics with Spark, Early Release Edition》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Ebook Advanced Analytics with Spark, Early Release Edition.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://keg.cs.tsinghua.edu.cn/jietang/&#34;&gt;《国内机器学习算法及应用领域人物篇:唐杰》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:清华大学副教授，是图挖掘方面的专家。他主持设计和实现的Arnetminer是国内领先的图挖掘系统，该系统也是多个会议的支持商.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cse.ust.hk/~qyang/&#34;&gt;《国内机器学习算法及应用领域人物篇:杨强》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:迁移学习的国际领军人物.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://cs.nju.edu.cn/zhouzh/&#34;&gt;《国内机器学习算法及应用领域人物篇:周志华》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:在半监督学习，multi-label学习和集成学习方面在国际上有一定的影响力.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://ir.hit.edu.cn/~wanghaifeng/whf_pub.htm&#34;&gt;《国内机器学习算法及应用领域人物篇:王海峰》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:信息检索，自然语言处理，机器翻译方面的专家.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cs.jhu.edu/~junwu/&#34;&gt;《国内机器学习算法及应用领域人物篇:吴军》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:吴军博士是当前Google中日韩文搜索算法的主要设计者。在Google其间，他领导了许多研发项目，包括许多与中文相关的产品和自然语言处理的项目,他的&lt;a href=&#34;https://sites.google.com/site/junwu02&#34;&gt;新个人主页&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.eecs.berkeley.edu/~junyanz/cat/cat_papers.html&#34;&gt;《Cat Paper Collection》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:喵星人相关论文集.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.dato.com/how-to-evaluate-machine-learning-models-part-1-orientation&#34;&gt;《How to Evaluate Machine Learning Models, Part 1: Orientation》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:如何评价机器学习模型系列文章,&lt;a href=&#34;http://blog.dato.com/how-to-evaluate-machine-learning-models-part-2a-classification-metrics&#34;&gt;How to Evaluate Machine Learning Models, Part 2a: Classification Metrics&lt;/a&gt;,&lt;a href=&#34;http://blog.dato.com/how-to-evaluate-machine-learning-models-part-2b-ranking-and-regression-metrics&#34;&gt;How to Evaluate Machine Learning Models, Part 2b: Ranking and Regression Metrics&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.twitter.com/2015/building-a-new-trends-experience&#34;&gt;《Building a new trends experience》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Twitter新trends的基本实现框架.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.packtpub.com/big-data-and-business-intelligence/storm-blueprints-patterns-distributed-real-time-computation&#34;&gt;《Storm Blueprints: Patterns for Distributed Real-time Computation》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Storm手册，国内有&lt;a href=&#34;https://github.com/cjie888/storm-trident&#34;&gt;中文翻译版本&lt;/a&gt;,谢谢作者.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/haifengl/smile&#34;&gt;《SmileMiner》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Java机器学习算法库SmileMiner.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://nlp.csai.tsinghua.edu.cn/~ly/talks/cwmt14_tut.pdf&#34;&gt;《机器翻译学术论文写作方法和技巧》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:机器翻译学术论文写作方法和技巧，Simon Peyton Jones的&lt;a href=&#34;http://research.microsoft.com/en-us/um/people/simonpj/papers/giving-a-talk/giving-a-talk.htm&#34;&gt;How to write a good research paper&lt;/a&gt;同类视频&lt;a href=&#34;https://www.youtube.com/watch?v=g3dkRsTqdDA&#34;&gt;How to Write a Great Research Paper&lt;/a&gt;,&lt;a href=&#34;http://vdisk.weibo.com/s/ayG13we2volht&#34;&gt;how to paper talk&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.csdn.net/zouxy09/article/details/45288129&#34;&gt;《神经网络训练中的Tricks之高效BP（反向传播算法）》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:神经网络训练中的Tricks之高效BP,博主的其他博客也挺精彩的.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.52cs.org/?p=499&#34;&gt;《我和NLP的故事》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:作者是NLP方向的硕士，短短几年内研究成果颇丰,推荐新入门的朋友阅读.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cs.ucla.edu/~palsberg/h-number.html&#34;&gt;《The h Index for Computer Science 》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:UCLA的Jens Palsberg根据Google Scholar建立了一个计算机领域的H-index牛人列表,我们熟悉的各个领域的大牛绝大多数都在榜上，包括1位诺贝尔奖得主，35位图灵奖得主，近百位美国工程院/科学院院士，300多位ACM Fellow,在这里推荐的原因是大家可以在google通过搜索牛人的名字来获取更多的资源,这份资料很宝贵.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://ttic.uchicago.edu/~mbansal/papers/acl14_structuredTaxonomy.pdf&#34;&gt;《Structured Learning for Taxonomy Induction with Belief Propagation》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:用大型语料库学习概念的层次关系，如鸟是鹦鹉的上级，鹦鹉是虎皮鹦鹉的上级。创新性在于模型构造，用因子图刻画概念之间依存关系，因引入兄弟关系，图有环，所以用有环扩散（loopy propagation）迭代计算边际概率（marginal probability）.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.stata.com/stata14/bayesian-analysis/&#34;&gt;《Bayesian analysis》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍: 这是一款贝叶斯分析的商业软件,官方写的&lt;a href=&#34;http://www.stata.com/manuals14/bayes.pdf&#34;&gt;贝叶斯分析的手册&lt;/a&gt;有250多页,虽然R语言 已经有类似的&lt;a href=&#34;http://cran.r-project.org/web/views/Bayesian.html&#34;&gt;项目&lt;/a&gt;,但毕竟可以增加一个可选项.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.quora.com/Boris-Babenko/Posts/deep-net-highlights-from-2014&#34;&gt;《deep net highlights from 2014》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:deep net highlights from 2014.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/pdf/1504.08083v1.pdf&#34;&gt;《Fast R-CNN》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:This paper proposes Fast R-CNN, a clean and fast framework for object detection.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://realpython.com/blog/python/fingerprinting-images-for-near-duplicate-detection/&#34;&gt;《Fingerprinting Images for Near-Duplicate Detection》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:图像指纹的重复识别,作者&lt;a href=&#34;https://github.com/realpython/image-fingerprinting/blob/master/code/output.csv&#34;&gt;源码&lt;/a&gt;,国内&lt;a href=&#34;http://www.cnblogs.com/wing1995/p/4471034.html&#34;&gt;翻译版本&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cs.ubc.ca/~lowe/vision.html&#34;&gt;《The Computer Vision Industry 》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:提供计算机视觉、机器视觉应用的公司信息汇总.应用领域包括：自动辅助驾驶和交通管理、眼球和头部跟踪、影视运动分析、影视业、手势识别、通用视觉系统、各种工业自动化和检验、医药和生物、移动设备目标识别和AR、人群跟踪、摄像、安全监控、生物监控、三维建模、web和云应用.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/mwaskom/seaborn&#34;&gt;《Seaborn: statistical data visualization》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Python版可视化数据统计开源库.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.juanklopper.com/opencourseware/mathematics-2/ipython-lecture-notes/&#34;&gt;《IPython lecture notes for OCW MIT 18.06》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:麻省理工Gilbert Strang线性代数课程笔记,Gilbert Strang《Linear Algebra》课程主页&lt;a href=&#34;http://ocw.mit.edu/courses/mathematics/18-06sc-linear-algebra-fall-2011/index.htm&#34;&gt;视频+讲义&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://deeplearning4j.org/canova.html&#34;&gt;《Canova: A Vectorization Lib for ML》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:面向机器学习/深度学习的数据向量化工具Canova,&lt;a href=&#34;https://github.com/deeplearning4j/Canova&#34;&gt;github&lt;/a&gt;, 支持CSV文件、MNIST数据、TF-IDF/Bag of Words/word2vec文本向量化.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://java.dzone.com/articles/dzone-refcardz-distributed&#34;&gt;《DZone Refcardz: Distributed Machine Learning with Apache Mahout》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:快速入门：基于Apache Mahout的分布式机器学习.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://nbviewer.ipython.org/github/gmonce/scikit-learn-book/tree/master/&#34;&gt;《Learning scikit-learn: Machine Learning in Python》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:基于scikit-learn讲解了一些机器学习技术，如SVM，NB，PCA，DT，以及特征工程、特征选择和模型选择问题.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://speakerdeck.com/nivdul/lightning-fast-machine-learning-with-spark&#34;&gt;《Lightning fast Machine Learning with Spark》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:基于Spark的高效机器学习,&lt;a href=&#34;https://www.parleys.com/tutorial/lightning-fast-machine-learning-spark&#34;&gt;视频地址&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.wepay.com/how-were-using-machine-learning-to-fight-shell-selling/&#34;&gt;《How we’re using machine learning to fight shell selling》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:WePay用机器学习对抗信用卡&amp;rdquo;shell selling&amp;rdquo;诈骗.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.datasciencecentral.com/profiles/blog/show?id=6448529:BlogPost:273276&#34;&gt;《Data Scientists Thoughts that Inspired Me》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:16位数据科学家语录精选.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.journalofbigdata.com/content/2/1/1&#34;&gt;《Deep learning applications and challenges in big data analytics》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:深度学习在大数据分析领域的应用和挑战.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://resrc.io/list/10/list-of-free-programming-books/#machine-learning&#34;&gt;《Free book:Machine Learning,Mathematics》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:免费的机器学习与数学书籍,除此之外还有其他的&lt;a href=&#34;https://github.com/vhf/resrc&#34;&gt;免费编程书籍&lt;/a&gt;,编程语言,设计,操作系统等.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/pdf/1505.01749.pdf&#34;&gt;《Object detection via a multi-region &amp;amp; semantic segmentation-aware CNN model》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:一篇关于CNN模型对象识别Paper.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.shakirm.com/2015/05/a-statistical-view-of-deep-learning-v-generalisation-and-regularisation/&#34;&gt;《A Statistical View of Deep Learning (V): Generalisation and Regularisation》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:深度学习的统计分析V:泛化和正则化.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1505.00387&#34;&gt;《Highway Networks》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:用SGD能高效完成训练的大规模(多层)深度网络HN.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.erogol.com/what-i-read-for-deep-learning/&#34;&gt;《What I Read For Deep-Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:深度学习解读文章.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://dataconomy.com/an-introduction-to-recommendation-engines&#34;&gt;《An Introduction to Recommendation Engines》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Coursera上的推荐系统导论（Introduction to Recommender Systems）公开课.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.holehouse.org/mlclass/index.html&#34;&gt;《Stanford Machine Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Andrew Ng经典机器学习课程笔记.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://yaroslavvb.blogspot.de/2015/05/iclr-2015_12.html&#34;&gt;《ICLR 2015》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:ICLR 2015见闻录,&lt;a href=&#34;http://yaroslavvb.blogspot.de/&#34;&gt;博客&lt;/a&gt;的其他机器学习文章也不错.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cripac.ia.ac.cn/People/sw/Xu2015PSR.pdf&#34;&gt;《Stanford Machine Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:推荐系统&amp;rdquo;个性化语义排序&amp;rdquo;模型.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://senseable.mit.edu/tweetbursts/&#34;&gt;《The More Excited We Are, The Shorter We Tweet》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:激情时分更惜字——MIT的最新Twitter研究结果.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://hlt.suda.edu.cn/paper.html&#34;&gt;《苏州大学人类语言技术研究论文主页》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:苏州大学人类语言技术研究相关论文.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1505.00387&#34;&gt;《Neural Turing Machines implementation》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:实现神经图灵机(NTM),&lt;a href=&#34;https://github.com/fumin/ntm&#34;&gt;项目地址&lt;/a&gt;,此外推荐相关神经图灵机&lt;a href=&#34;http://www.i-programmer.info/news/105-artificial-intelligence/7923-neural-turing-machines-learn-their-algorithms.html&#34;&gt;算法&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cse.wustl.edu/~furukawa/cse559a/2015_spring/&#34;&gt;《Computer Vision - CSE 559A, Spring 2015》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:华盛顿大学的机器视觉(2015),参考资料&lt;a href=&#34;http://szeliski.org/Book/&#34;&gt;Computer Vision: Algorithms and Applications&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.mmds.org/&#34;&gt;《Mining of Massive Datasets》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:&amp;ldquo;Mining of Massive Datasets&amp;rdquo;发布第二版,Jure Leskovec, Anand Rajaraman, Jeff Ullman 新版增加Jure Leskovec作为合作作者，新增社交网络图数据挖掘、降维和大规模机器学习三章,&lt;a href=&#34;http://pan.baidu.com/s/1GvtpG&#34;&gt;电子版&lt;/a&gt;依旧免费.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://rt.dgyblog.com/ref/ref-learning-deep-learning.html&#34;&gt;《Learning Deep Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:一个深度学习资源页,资料很丰富.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://vdisk.weibo.com/s/ayG13we2ler9b&#34;&gt;《Learning Deep Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:免费电子书&amp;rdquo;Learning Deep Learning&amp;rdquo;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.astroml.org/sklearn_tutorial/index.html&#34;&gt;《Tutorial: Machine Learning for Astronomy with Scikit-learn》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Machine Learning for Astronomy with scikit-learn.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://info.salford-systems.com/an-introduction-to-random-forests-for-beginners&#34;&gt;《An Introduction to Random Forests for Beginners》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:免费电子书&amp;rdquo;随机森林入门指南&amp;rdquo;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://rayli.net/blog/data/top-10-data-mining-algorithms-in-plain-english/&#34;&gt;《Top 10 data mining algorithms in plain English》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:白话数据挖掘十大算法.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.mapr.com/blog/inside-look-at-components-of-recommendation-engine#.VVmZ5vmqqko&#34;&gt;《An Inside Look at the Components of a Recommendation Engine》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:基于Mahout和Elasticsearch的推荐系统,&lt;a href=&#34;http://www.csdn.net/article/2015-05-14/2824676&#34;&gt;国内译版&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aaltodoc.aalto.fi/bitstream/handle/123456789/15585/isbn9789526061498.pdf&#34;&gt;《Advances in Extreme Learning Machines》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:博士学位论文:ELM研究进展.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://vimeo.com/59324550&#34;&gt;《10-minute tour of pandas》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Pandas十分钟速览,&lt;a href=&#34;http://nbviewer.ipython.org/urls/gist.github.com/wesm/4757075/raw/a72d3450ad4924d0e74fb57c9f62d1d895ea4574/PandasTour.ipynb&#34;&gt;ipn&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://pudo.org/blog/2015/05/15/document-mining.html&#34;&gt;《Data doesn&amp;rsquo;t grow in tables: harvesting journalistic insight from documents》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:面向数据新闻的文本挖掘.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://grail.cs.washington.edu/projects/timelapse/&#34;&gt;《Time-lapse Mining from Internet Photos》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:用网络图片合成延时视频(SIGGRAPH 2015).&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.visiondummy.com/2014/04/curse-dimensionality-affect-classification/&#34;&gt;《The Curse of Dimensionality in classification》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:分类系统的维数灾难.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.computervisionblog.com/2015/05/deep-learning-vs-big-data-who-owns-what.html&#34;&gt;《Deep Learning vs Big Data: Who owns what?》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:深度学习vs.大数据——从数据到知识：版权的思考,[翻译版](&lt;a href=&#34;http://www.csdn.net/article/2015-05-19/2824707&#34;&gt;http://www.csdn.net/article/2015-05-19/2824707&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.nature.com/ctg/journal/v5/n1/abs/ctg201319a.html&#34;&gt;《A Primer on Predictive Models》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:预测模型入门.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.terminal.com/demistifying-long-short-term-memory-lstm-recurrent-neural-networks/&#34;&gt;《Demistifying LSTM Neural Networks》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:深入浅出LSTM.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLhiWXaTdsWB8PnrVZquVyqlRFWXM4ijYz&#34;&gt;《ICLR 2015》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:2015年ICLR会议&lt;a href=&#34;http://pan.baidu.com/s/1bnbbRyR&#34;&gt;视频&lt;/a&gt;与&lt;a href=&#34;http://www.iclr.cc/doku.php?id=iclr2015:main&#34;&gt;讲义&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://dataremixed.com/2015/05/on-visualizing-data-well/&#34;&gt;《On Visualizing Data Well》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Ben Jones的数据可视化建议.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://bigdata-madesimple.com/decoding-dimensionality-reduction-pca-and-svd/&#34;&gt;《Decoding Dimensionality Reduction, PCA and SVD》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:解读数据降维/PCA/SVD.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://ryancompton.net/assets/ml_cheat_sheet/supervised_learning.html&#34;&gt;《Supervised learning superstitions cheat sheet》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:IPN:监督学习方法示例/对比参考表,覆盖logistic回归, 决策树, SVM, KNN, Naive Bayes等方法.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1505.04771&#34;&gt;《DopeLearning: A Computational Approach to Rap Lyrics Generation》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:基于RankSVM和DNN自动(重组)生成Rap歌词.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.sics.se/~mange/papers/RI_intro.pdf&#34;&gt;《An Introduction to Random Indexing》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:随机索引RI词空间模型专题.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.vdiscover.org/&#34;&gt;《VDiscover》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:基于机器学习的漏洞检测工具VDiscover.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dmlc/minerva&#34;&gt;《Minerva》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:深度学习系统minerva。拥有python编程接口。多GPU几乎达到线性加速。在4块GPU上能在4天内将GoogLeNet训练到68.7%的top-1以及89.0%的top-5准确率。和同为dmlc项目的cxxnet相比，采用动态数据流引擎，提供更多灵活性。未来将和cxxnet一起整合为mxnet项目，互取优势.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cv-foundation.org/openaccess/CVPR2015.py&#34;&gt;《CVPR 2015 paper》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:2015年国际计算机视觉与模式识别会议paper.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.quora.com/What-are-the-advantages-of-different-classification-algorithms/answer/Xavier-Amatriain&#34;&gt;《What are the advantages of different classification algorithms?》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Netflix工程总监眼中的分类算法：深度学习优先级最低,&lt;a href=&#34;http://www.csdn.net/article/2015-05-24/2824758&#34;&gt;中文版&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.codalab.org/competitions/3221#results&#34;&gt;《Results for Microsoft COCO Image Captioning Challenge》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Codalab图像标注竞赛排行+各家论文,Reddit上flukeskywalker整理了各家技术&lt;a href=&#34;http://www.reddit.com/r/MachineLearning/comments/376b28/comparison_of_official_test_scores_of_current/&#34;&gt;相关论文&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1504.04343&#34;&gt;《Caffe con Troll: Shallow Ideas to Speed Up Deep Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:基于Caffe的加速深度学习系统CcT.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1412.7024&#34;&gt;《Low precision storage for deep learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:深度学习(模型)低精度(训练与)存储.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.mbmlbook.com/index.html&#34;&gt;《Model-Based Machine Learning (Early Access)》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:新书预览:模型机器学习.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.princeton.edu/~sbubeck/SurveyBCB12.pdf&#34;&gt;《Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:免费电子书多臂老虎机,此外推荐&lt;a href=&#34;https://sites.google.com/site/banditstutorial/&#34;&gt;Introduction to Bandits: Algorithms and Theory&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.datacamp.com/courses/kaggle-tutorial-on-machine-learing-the-sinking-of-the-titanic&#34;&gt;《Kaggle R Tutorial on Machine Learing》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:基于Kaggle&amp;rsquo;s Titanic Competition的交互式R机器学习教程,介绍&lt;a href=&#34;http://blog.kaggle.com/2015/05/27/interactive-r-tutorial-machine-learning-for-the-titanic-competition/&#34;&gt;《Interactive R Tutorial: Machine Learning for the Titanic Competition》&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://suanfazu.com/t/deep-learning/9401&#34;&gt;《Deep Learning（深度学习）学习笔记整理系列》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Deep Learning（深度学习）学习笔记整理系列.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-with-gpus/&#34;&gt;《Introduction to Neural Machine Translation with GPUs 》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:神经(感知)机器翻译介绍.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=n1ViNeWhC24&amp;amp;hd=1&#34;&gt;《Andrew Ng: Deep Learning, Self-Taught Learning and Unsupervised Feature Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Andrew Ng关于深度学习/自学习/无监督特征学习的报告,&lt;a href=&#34;http://pan.baidu.com/s/1jG8DUN8&#34;&gt;国内云&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1505.04630&#34;&gt;《Recurrent Neural Network Training with Dark Knowledge Transfer》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:论文:通过潜在知识迁移训练RNN.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/chrischris292/ShowMeTheMoney&#34;&gt;《Show Me The Money》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:面向金融数据的情感分析工具.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/bmabey/pyLDAvis&#34;&gt;《pyLDAvis》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:(Python)主题模型交互可视化库pyLDAvis.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://nbviewer.ipython.org/github/tfolkman/learningwithdata/blob/master/Logistic%20Gradient%20Descent.ipynb&#34;&gt;《Logistic Regression and Gradient Descent》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Logistic回归与优化实例教程.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://pan.baidu.com/s/1dDGVL53&#34;&gt;《贾扬清微信讲座记录》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:贾扬清（谷歌大脑科学家、caffe缔造者）微信讲座记录.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/udibr/sketch&#34;&gt;《sketch》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Theano/Blocks实现RNN手写字符串生成sketch.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://chris.de-vries.id.au/2015/05/web-scale-document-clustering.html&#34;&gt;《Web Scale Document Clustering: Clustering 733 Million Web Pages》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:基于TopSig的海量(7亿+)网页聚类.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://aclweb.org/anthology/N/N15/&#34;&gt;《NAACL 2015 Proceedings on ACL Anthology》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:NAACL 2015 论文papers.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.anlytcs.com/2015/05/stock-forecasting-with-machine-learning.html&#34;&gt;《Stock Forecasting With Machine Learning - Seven Possible Errors》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:机器学习预测股市的七个问题.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.reddit.com/r/MachineLearning/comments/378but/are_there_any_good_resources_for_learning_about/&#34;&gt;《Are there any good resources for learning about neural networks?》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:神经网络学习资料推荐.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1506.00019v1&#34;&gt;《A Critical Review of Recurrent Neural Networks for Sequence Learning》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:面向序列学习的RNN综述.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://gastonsanchez.com/Handling_and_Processing_Strings_in_R.pdf&#34;&gt;《Handling and Processing Strings in R》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:R文本处理手册.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/s16h/py-must-watch&#34;&gt;《Must-watch videos about Python》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:“必看”的Python视频集锦.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://malteschwarzkopf.de/research/assets/google-stack.pdf&#34;&gt;《The Google Stack》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Google(基础结构)栈.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://cs.stanford.edu/people/mmahoney/f13-stat260-cs294/&#34;&gt;《Randomized Algorithms for Matrices and Data》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:矩阵和数据的随机算法(UC Berkeley 2013).&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.datacamp.com/courses/intermediate-r&#34;&gt;《Intermediate R》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:DataCamp中级R语言教程.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.topologywithouttears.net/&#34;&gt;《Topology Without Tears》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:免费电子书:轻松掌握拓扑学,&lt;a href=&#34;http://www.topologywithouttears.net/topbookchinese.pdf&#34;&gt;中文版&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.inference.phy.cam.ac.uk/itprnn_lectures/&#34;&gt;《Information Theory, Pattern Recognition, and Neural Networks》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:&lt;a href=&#34;http://www.inference.phy.cam.ac.uk/itprnn/book.pdf&#34;&gt;Book&lt;/a&gt;,&lt;a href=&#34;https://www.youtube.com/user/jakobfoerster/videos&#34;&gt;video&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;www.github.com/scikit-learn/scikit-learn&#34;&gt;《Scikit-learn》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Scikit-learn 是基于Scipy为机器学习建造的的一个Python模块，他的特色就是多样化的分类，回归和聚类的算法包括支持向量机，逻辑回归，朴素贝叶斯分类器，随机森林，Gradient Boosting，聚类算法和DBSCAN。而且也设计出了Python numerical和scientific libraries Numpy and Scipy&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;www.github.com/lisa-lab/pylearn2&#34;&gt;《Pylearn2》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Pylearn是一个让机器学习研究简单化的基于Theano的库程序。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;www.github.com/numenta/nupic&#34;&gt;《NuPIC》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:NuPIC是一个以HTM学习算法为工具的机器智能平台。HTM是皮层的精确计算方法。HTM的核心是基于时间的持续学习算法和储存和撤销的时空模式。NuPIC适合于各种各样的问题,尤其是检测异常和预测的流数据来源。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;www.github.com/nilearn/nilearn&#34;&gt;《Nilearn》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Nilearn 是一个能够快速统计学习神经影像数据的Python模块。它利用Python语言中的scikit-learn 工具箱和一些进行预测建模，分类，解码，连通性分析的应用程序来进行多元的统计。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;www.github.com/pybrain/pybrain&#34;&gt;《PyBrain》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Pybrain是基于Python语言强化学习，人工智能，神经网络库的简称。 它的目标是提供灵活、容易使用并且强大的机器学习算法和进行各种各样的预定义的环境中测试来比较你的算法。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;www.github.com/clips/pattern&#34;&gt;《Pattern》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Pattern 是Python语言下的一个网络挖掘模块。它为数据挖掘，自然语言处理，网络分析和机器学习提供工具。它支持向量空间模型、聚类、支持向量机和感知机并且用KNN分类法进行分类。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;www.github.com/mila-udem/fuel&#34;&gt;《Fuel》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Fuel为你的机器学习模型提供数据。他有一个共享如MNIST, CIFAR-10 (图片数据集), Google’s One Billion Words (文字)这类数据集的接口。你使用他来通过很多种的方式来替代自己的数据。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;www.github.com/idiap/bob&#34;&gt;《Bob》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Bob是一个免费的信号处理和机器学习的工具。它的工具箱是用Python和C++语言共同编写的，它的设计目的是变得更加高效并且减少开发时间，它是由处理图像工具,音频和视频处理、机器学习和模式识别的大量软件包构成的。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;www.github.com/jaberg/skdata&#34;&gt;《Skdata》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Skdata是机器学习和统计的数据集的库程序。这个模块对于玩具问题，流行的计算机视觉和自然语言的数据集提供标准的Python语言的使用。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;www.github.com/luispedro/milk&#34;&gt;《MILK》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:MILK是Python语言下的机器学习工具包。它主要是在很多可得到的分类比如SVMS,K-NN,随机森林，决策树中使用监督分类法。 它还执行特征选择。 这些分类器在许多方面相结合,可以形成不同的例如无监督学习、密切关系金传播和由MILK支持的K-means聚类等分类系统。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;www.github.com/machinalis/iepy&#34;&gt;《IEPY》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:IEPY是一个专注于关系抽取的开源性信息抽取工具。它主要针对的是需要对大型数据集进行信息提取的用户和想要尝试新的算法的科学家。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;www.github.com/machinalis/quepy&#34;&gt;《Quepy》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Quepy是通过改变自然语言问题从而在数据库查询语言中进行查询的一个Python框架。他可以简单的被定义为在自然语言和数据库查询中不同类型的问题。所以，你不用编码就可以建立你自己的一个用自然语言进入你的数据库的系统。现在Quepy提供对于Sparql和MQL查询语言的支持。并且计划将它延伸到其他的数据库查询语言。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;www.github.com/hannes-brt/hebel&#34;&gt;《Hebel》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Hebel是在Python语言中对于神经网络的深度学习的一个库程序，它使用的是通过PyCUDA来进行GPU和CUDA的加速。它是最重要的神经网络模型的类型的工具而且能提供一些不同的活动函数的激活功能，例如动力，涅斯捷罗夫动力，信号丢失和停止法。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;www.github.com/rasbt/mlxtend&#34;&gt;《mlxtend》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:它是一个由有用的工具和日常数据科学任务的扩展组成的一个库程序。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;www.github.com/dnouri/nolearn&#34;&gt;《nolearn》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:这个程序包容纳了大量能对你完成机器学习任务有帮助的实用程序模块。其中大量的模块和scikit-learn一起工作，其它的通常更有用。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;www.github.com/kvh/ramp&#34;&gt;《Ramp》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Ramp是一个在Python语言下制定机器学习中加快原型设计的解决方案的库程序。他是一个轻型的pandas-based机器学习中可插入的框架，它现存的Python语言下的机器学习和统计工具（比如scikit-learn,rpy2等）Ramp提供了一个简单的声明性语法探索功能从而能够快速有效地实施算法和转换。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;www.github.com/machinalis/featureforge&#34;&gt;《Feature Forge》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:这一系列工具通过与scikit-learn兼容的API，来创建和测试机器学习功能。这个库程序提供了一组工具，它会让你在许多机器学习程序使用中很受用。当你使用scikit-learn这个工具时，你会感觉到受到了很大的帮助。（虽然这只能在你有不同的算法时起作用。）&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;www.github.com/yandex/rep&#34;&gt;《REP》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:REP是以一种和谐、可再生的方式为指挥数据移动驱动所提供的一种环境。它有一个统一的分类器包装来提供各种各样的操作，例如TMVA, Sklearn, XGBoost, uBoost等等。并且它可以在一个群体以平行的方式训练分类器。同时它也提供了一个交互式的情节。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;www.github.com/awslabs/machine-learning-samples&#34;&gt;《Python 学习机器样品》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:用亚马逊的机器学习建造的简单软件收集。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;www.github.com/dclambert/Python-ELM&#34;&gt;《Python-ELM》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:这是一个在Python语言下基于scikit-learn的极端学习机器的实现。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://forum.memect.com/thread/dimension-reduction/&#34;&gt;《Dimension Reduction》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:电子书降维方法,此外还推荐&lt;a href=&#34;http://www.stat.washington.edu/courses/stat539/spring14/Resources/tutorial_nonlin-dim-red.pdf&#34;&gt;Dimensionality Reduction A Short Tutorial&lt;/a&gt;、&lt;a href=&#34;http://lvdmaaten.github.io/drtoolbox/&#34;&gt;Matlab Toolbox for Dimensionality Reduction&lt;/a&gt;、&lt;a href=&#34;http://www.cs.berkeley.edu/~jordan/papers/wang-sha-jordan-nips11.pdf&#34;&gt;Unsupervised Kernel Dimension Reduction&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://deeplearning.net/datasets/&#34;&gt;《Datasets Used For Benchmarking Deep Learning Algorithms》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:deeplearning.net整理的深度学习数据集列表.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/advancedlogic/go-freeling&#34;&gt;《Golang Natural Language Processing》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:Go语言编写的自然语言处理工具.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1412.4930&#34;&gt;《Rehabilitation of Count-based Models for Word Vector Representations》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:词频模型对词向量的反击,参考&lt;a href=&#34;https://levyomer.files.wordpress.com/2015/03/improving-distributional-similarity-tacl-2015.pdf&#34;&gt;Improving Distributional Similarity with Lessons Learned from Word Embeddings &lt;/a&gt;。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://static1.squarespace.com/static/51156277e4b0b8b2ffe11c00/t/55344152e4b0ff30bb9ec163/1429487954122/ASA_Kuhn.pdf&#34;&gt;《Three Aspects of Predictive Modeling》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:预测模型的三个方面.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://cs224d.stanford.edu/&#34;&gt;《CS224d: Deep Learning for Natural Language Processing》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:斯坦福大学深度学习与自然语言处理课程,部分课程笔记&lt;a href=&#34;http://www.52nlp.cn/%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%AC%E4%BA%8C%E8%AE%B2%E8%AF%8D%E5%90%91%E9%87%8F&#34;&gt;词向量&lt;/a&gt;、&lt;a href=&#34;http://www.52nlp.cn/%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%AC%E4%B8%80%E8%AE%B2%E5%BC%95%E8%A8%80&#34;&gt;引言&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://googleresearch.blogspot.jp/2015/06/google-computer-vision-research-at-cvpr.html&#34;&gt;《Google Computer Vision research at CVPR 2015》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:CVPR2015上Google的CV研究列表.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://public.hudl.com/bits/archives/2015/06/05/highlights/&#34;&gt;《Using Deep Learning to Find Basketball Highlights》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:利用(Metamind)深度学习自动发现篮球赛精彩片段.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1512.04150&#34;&gt;《Learning Deep Features for Discriminative Localization》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;介绍:对本土化特征学习的分析&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Configure Venv</title>
      <link>http://danigong.github.io/post/configure_venv/</link>
      <pubDate>Sun, 10 Jul 2016 12:43:13 +0800</pubDate>
      
      <guid>http://danigong.github.io/post/configure_venv/</guid>
      <description>&lt;p&gt;安装virtualenv：
    &lt;code&gt;pip install virtualenv&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;创建虚拟环境
    &lt;code&gt;virtualenv venv&lt;/code&gt;
    venv是新创建的虚拟环境的名称。 同时会创建一个与虚拟环境名称相同的文件夹venv, 里面存储了一个独立的Python执行环境。&lt;/p&gt;

&lt;p&gt;进入虚拟环境
    &lt;code&gt;source venv/bin/activate&lt;/code&gt;
    进入虚拟环境后，命令行的提示符会加入虚拟环境的名称，例如：&lt;code&gt;(venv)user@machine:~$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;退出虚拟环境$
    &lt;code&gt;deactivate&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;删除虚拟环境
    &lt;code&gt;rm -r venv&lt;/code&gt;
    直接删除虚拟环境所在的文件夹venv就删除了我们创建的venv虚拟环境。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deploy Hugo Site on GitHub Pages</title>
      <link>http://danigong.github.io/post/deploy_hugo_site_to_github/</link>
      <pubDate>Sat, 28 May 2016 20:27:28 +0800</pubDate>
      
      <guid>http://danigong.github.io/post/deploy_hugo_site_to_github/</guid>
      <description>&lt;hr /&gt;

&lt;ol&gt;
&lt;li&gt;Create a Repository: danigong.github.io (replace danigong with your own github username)&lt;/li&gt;
&lt;li&gt;Change directory to root directory of the site.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;$ hugo --theme=hyde --baseUrl=&amp;quot;http://danigong.github.io/&amp;quot;&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;$ cd public
$ git init
$ git remote add origin https://github.com/danigong/danigong.github.io.git
$ git add -A
$ git commit -m &amp;quot;first commit&amp;quot;
$ git push -u origin master
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Mongodb Setup</title>
      <link>http://danigong.github.io/post/mongodb_setup/</link>
      <pubDate>Sat, 28 May 2016 20:14:28 +0800</pubDate>
      
      <guid>http://danigong.github.io/post/mongodb_setup/</guid>
      <description>&lt;hr /&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;brew update&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;brew install mongodb&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;setup python driver for mongoldb:
&lt;code&gt;
pip install pymongo
&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Pyramid Dev Environment Setup</title>
      <link>http://danigong.github.io/post/pyramid_dev_env_set/</link>
      <pubDate>Sat, 28 May 2016 20:09:35 +0800</pubDate>
      
      <guid>http://danigong.github.io/post/pyramid_dev_env_set/</guid>
      <description>&lt;hr /&gt;

&lt;ol&gt;
&lt;li&gt;Download Setuptool: &lt;a href=&#34;http://peak.telecommunity.com/dist/ez_setup.py&#34;&gt;http://peak.telecommunity.com/dist/ez_setup.py&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Install Setuptool: &lt;code&gt;sudo python ez_setup.py&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Install virtulenv: &lt;code&gt;sudo easy_install virtualenv&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Install Pyramid: &lt;code&gt;virtualenv —no-site-packages env&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cd env&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;bin/easy_install pyramid&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Will contain pyramid, template(Chameleon、Mako), PasteDeploy&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>A Guide to Python&#39;s Function Decorators</title>
      <link>http://danigong.github.io/post/python_decorator_guide/</link>
      <pubDate>Wed, 25 May 2016 22:26:53 +0800</pubDate>
      
      <guid>http://danigong.github.io/post/python_decorator_guide/</guid>
      <description>

&lt;hr /&gt;

&lt;p&gt;Python is rich with powerful features and expressive syntax. One of my favorites is decorators. In the context of design patterns, decorators dynamically alter the functionality of a function, method or class without having to directly use subclasses. This is ideal when you need to extend the functionality of functions that you don&amp;rsquo;t want to modify. We can implement the decorator pattern anywhere, but Python facilitates the implementation by providing much more expressive features and syntax for that.&lt;/p&gt;

&lt;p&gt;In this post I will be discussing Python&amp;rsquo;s function decorators in depth, accompanied by a bunch of examples on the way to clear up the concepts. All examples are in Python 2.7 but the same concepts should apply to Python 3 with some change in the syntax.&lt;/p&gt;

&lt;p&gt;Essentially, decorators work as wrappers, modifying the behavior of the code before and after a target function execution, without the need to modify the function itself, augmenting the original functionality, thus decorating it.&lt;/p&gt;

&lt;h2 id=&#34;what-you-need-to-know-about-functions:24448b6c2a661c98161fc3da9e5d92cf&#34;&gt;What you need to know about functions&lt;/h2&gt;

&lt;p&gt;Before diving in, there are some prerequisites that should be clear. In Python, functions are first class citizens, they are objects and that means we can do a lot of useful stuff with them.&lt;/p&gt;

&lt;h3 id=&#34;assign-functions-to-variables:24448b6c2a661c98161fc3da9e5d92cf&#34;&gt;Assign functions to variables&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;def greet(name):
    return &amp;quot;hello &amp;quot;+name

greet_someone = greet
print greet_someone(&amp;quot;John&amp;quot;)

# Outputs: hello John
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;define-functions-inside-other-functions:24448b6c2a661c98161fc3da9e5d92cf&#34;&gt;Define functions inside other functions&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;def greet(name):
    def get_message():
        return &amp;quot;Hello &amp;quot;

    result = get_message()+name
    return result

print greet(&amp;quot;John&amp;quot;)

# Outputs: Hello John
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;functions-can-be-passed-as-parameters-to-other-functions:24448b6c2a661c98161fc3da9e5d92cf&#34;&gt;Functions can be passed as parameters to other functions&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;def greet(name):
   return &amp;quot;Hello &amp;quot; + name 

def call_func(func):
    other_name = &amp;quot;John&amp;quot;
    return func(other_name)  

print call_func(greet)

# Outputs: Hello John
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;functions-can-return-other-functions:24448b6c2a661c98161fc3da9e5d92cf&#34;&gt;Functions can return other functions&lt;/h3&gt;

&lt;p&gt;In other words, functions generating other functions.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def compose_greet_func():
    def get_message():
        return &amp;quot;Hello there!&amp;quot;

    return get_message

greet = compose_greet_func()
print greet()

# Outputs: Hello there!
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;inner-functions-have-access-to-the-enclosing-scope:24448b6c2a661c98161fc3da9e5d92cf&#34;&gt;Inner functions have access to the enclosing scope&lt;/h3&gt;

&lt;p&gt;More commonly known as a closure. A very powerful pattern that we will come across while building decorators. Another thing to note, Python only allows read access to the outer scope and not assignment. Notice how we modified the example above to read a &amp;ldquo;name&amp;rdquo; argument from the enclosing scope of the inner function and return the new function.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def compose_greet_func(name):
    def get_message():
        return &amp;quot;Hello there &amp;quot;+name+&amp;quot;!&amp;quot;

    return get_message

greet = compose_greet_func(&amp;quot;John&amp;quot;)
print greet()

# Outputs: Hello there John!
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;composition-of-decorators:24448b6c2a661c98161fc3da9e5d92cf&#34;&gt;Composition of Decorators&lt;/h2&gt;

&lt;p&gt;Function decorators are simply wrappers to existing functions. Putting the ideas mentioned above together, we can build a decorator. In this example let&amp;rsquo;s consider a function that wraps the string output of another function by p tags.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def get_text(name):
   return &amp;quot;lorem ipsum, {0} dolor sit amet&amp;quot;.format(name)

def p_decorate(func):
   def func_wrapper(name):
       return &amp;quot;&amp;lt;p&amp;gt;{0}&amp;lt;/p&amp;gt;&amp;quot;.format(func(name))
   return func_wrapper

my_get_text = p_decorate(get_text)

print my_get_text(&amp;quot;John&amp;quot;)

# &amp;lt;p&amp;gt;Outputs lorem ipsum, John dolor sit amet&amp;lt;/p&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That was our first decorator. A function that takes another function as an argument, generates a new function, augmenting the work of the original function, and returning the generated function so we can use it anywhere. To have get_text itself be decorated by p_decorate, we just have to assign get_text to the result of p_decorate.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;get_text = p_decorate(get_text)

print get_text(&amp;quot;John&amp;quot;)

# Outputs lorem ipsum, John dolor sit amet
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Another thing to notice is that our decorated function takes a name argument. All what we had to do in the decorator is to let the wrapper of get_text pass that argument.&lt;/p&gt;

&lt;h2 id=&#34;python-s-decorator-syntax:24448b6c2a661c98161fc3da9e5d92cf&#34;&gt;Python&amp;rsquo;s Decorator Syntax&lt;/h2&gt;

&lt;p&gt;Python makes creating and using decorators a bit cleaner and nicer for the programmer through some syntactic sugar To decorate get_text we don&amp;rsquo;t have to &lt;code&gt;get_text = p_decorator(get_text)&lt;/code&gt; There is a neat shortcut for that, which is to mention the name of the decorating function before the function to be decorated. The name of the decorator should be perpended with an @ symbol.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def p_decorate(func):
   def func_wrapper(name):
       return &amp;quot;&amp;lt;p&amp;gt;{0}&amp;lt;/p&amp;gt;&amp;quot;.format(func(name))
   return func_wrapper

@p_decorate
def get_text(name):
   return &amp;quot;lorem ipsum, {0} dolor sit amet&amp;quot;.format(name)

print get_text(&amp;quot;John&amp;quot;)

# Outputs &amp;lt;p&amp;gt;lorem ipsum, John dolor sit amet&amp;lt;/p&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now let&amp;rsquo;s consider we wanted to decorate our get_text function by 2 other functions to wrap a div and strong tag around the string output.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def p_decorate(func):
   def func_wrapper(name):
       return &amp;quot;&amp;lt;p&amp;gt;{0}&amp;lt;/p&amp;gt;&amp;quot;.format(func(name))
   return func_wrapper

def strong_decorate(func):
    def func_wrapper(name):
        return &amp;quot;&amp;lt;strong&amp;gt;{0}&amp;lt;/strong&amp;gt;&amp;quot;.format(func(name))
    return func_wrapper

def div_decorate(func):
    def func_wrapper(name):
        return &amp;quot;&amp;lt;div&amp;gt;{0}&amp;lt;/div&amp;gt;&amp;quot;.format(func(name))
    return func_wrapper
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With the basic approach, decorating get_text would be along the lines of&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;get_text = div_decorate(p_decorate(strong_decorate(get_text)))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With Python&amp;rsquo;s decorator syntax, same thing can be achieved with much more expressive power.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@div_decorate
@p_decorate
@strong_decorate
def get_text(name):
   return &amp;quot;lorem ipsum, {0} dolor sit amet&amp;quot;.format(name)

print get_text(&amp;quot;John&amp;quot;)

# Outputs &amp;lt;div&amp;gt;&amp;lt;p&amp;gt;&amp;lt;strong&amp;gt;lorem ipsum, John dolor sit amet&amp;lt;/strong&amp;gt;&amp;lt;/p&amp;gt;&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;One important thing to notice here is that the order of setting our decorators matters. If the order was different in the example above, the output would have been different.&lt;/p&gt;

&lt;h2 id=&#34;decorating-methods:24448b6c2a661c98161fc3da9e5d92cf&#34;&gt;Decorating Methods&lt;/h2&gt;

&lt;p&gt;In Python, methods are functions that expect their first parameter to be a reference to the current object. We can build decorators for methods the same way, while taking self into consideration in the wrapper function.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def p_decorate(func):
   def func_wrapper(self):
       return &amp;quot;&amp;lt;p&amp;gt;{0}&amp;lt;/p&amp;gt;&amp;quot;.format(func(self))
   return func_wrapper

class Person(object):
    def __init__(self):
        self.name = &amp;quot;John&amp;quot;
        self.family = &amp;quot;Doe&amp;quot;

    @p_decorate
    def get_fullname(self):
        return self.name+&amp;quot; &amp;quot;+self.family

my_person = Person()
print my_person.get_fullname()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A much better approach would be to make our decorator useful for functions and methods alike. This can be done by putting *args and **kwargs as parameters for the wrapper, then it can accept any arbitrary number of arguments and keyword arguments.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def p_decorate(func):
   def func_wrapper(*args, **kwargs):
       return &amp;quot;&amp;lt;p&amp;gt;{0}&amp;lt;/p&amp;gt;&amp;quot;.format(func(*args, **kwargs))
   return func_wrapper

class Person(object):
    def __init__(self):
        self.name = &amp;quot;John&amp;quot;
        self.family = &amp;quot;Doe&amp;quot;

    @p_decorate
    def get_fullname(self):
        return self.name+&amp;quot; &amp;quot;+self.family

my_person = Person()

print my_person.get_fullname()
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;passing-arguments-to-decorators:24448b6c2a661c98161fc3da9e5d92cf&#34;&gt;Passing arguments to decorators&lt;/h2&gt;

&lt;p&gt;Looking back at the example before the one above, you can notice how redundant the decorators in the example are. 3 decorators(div_decorate, p_decorate, strong_decorate) each with the same functionality but wrapping the string with different tags. We can definitely do much better than that. Why not have a more general implementation for one that takes the tag to wrap with as a string? Yes please!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def tags(tag_name):
    def tags_decorator(func):
        def func_wrapper(name):
            return &amp;quot;&amp;lt;{0}&amp;gt;{1}&amp;lt;/{0}&amp;gt;&amp;quot;.format(tag_name, func(name))
        return func_wrapper
    return tags_decorator

@tags(&amp;quot;p&amp;quot;)
def get_text(name):
    return &amp;quot;Hello &amp;quot;+name

print get_text(&amp;quot;John&amp;quot;)

# Outputs &amp;lt;p&amp;gt;Hello John&amp;lt;/p&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It took a bit more work in this case. Decorators expect to receive a function as an argument, that is why we will have to build a function that takes those extra arguments and generate our decorator on the fly. In the example above tags, is our decorator generator.&lt;/p&gt;

&lt;h2 id=&#34;debugging-decorated-functions:24448b6c2a661c98161fc3da9e5d92cf&#34;&gt;Debugging decorated functions&lt;/h2&gt;

&lt;p&gt;At the end of the day decorators are just wrapping our functions, in case of debugging that can be problematic since the wrapper function does not carry the name, module and docstring of the original function. Based on the example above if we do:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print get_text.__name__
# Outputs func_wrapper
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The output was expected to be get_text yet, the attributes &lt;strong&gt;name&lt;/strong&gt;, &lt;strong&gt;doc&lt;/strong&gt;, and &lt;strong&gt;module&lt;/strong&gt; of get_text got overridden by those of the wrapper(func_wrapper. Obviously we can re-set them within func_wrapper but Python provides a much nicer way.&lt;/p&gt;

&lt;p&gt;Functools to the rescue
Fortunately Python (as of version 2.5) includes the functools module which contains functools.wraps. Wraps is a decorator for updating the attributes of the wrapping function(func_wrapper) to those of the original function(get_text). This is as simple as decorating func_wrapper by @wraps(func). Here is the updated example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from functools import wraps

def tags(tag_name):
    def tags_decorator(func):
        @wraps(func)
        def func_wrapper(name):
            return &amp;quot;&amp;lt;{0}&amp;gt;{1}&amp;lt;/{0}&amp;gt;&amp;quot;.format(tag_name, func(name))
        return func_wrapper
    return tags_decorator

@tags(&amp;quot;p&amp;quot;)
def get_text(name):
    &amp;quot;&amp;quot;&amp;quot;returns some text&amp;quot;&amp;quot;&amp;quot;
    return &amp;quot;Hello &amp;quot;+name

print get_text.__name__ # get_text
print get_text.__doc__ # returns some text
print get_text.__module__ # __main__
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can notice from the output that the attributes of get_text are the correct ones now.&lt;/p&gt;

&lt;h2 id=&#34;where-to-use-decorators:24448b6c2a661c98161fc3da9e5d92cf&#34;&gt;Where to use decorators&lt;/h2&gt;

&lt;p&gt;The examples in this post are pretty simple relative to how much you can do with decorators. They can give so much power and elegance to your program. In general, decorators are ideal for extending the behavior of functions that we don&amp;rsquo;t want to modify. For a great list of useful decorators I suggest you check out the Python Decorator Library&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Python Property</title>
      <link>http://danigong.github.io/post/python_property/</link>
      <pubDate>Mon, 13 Jul 2015 22:55:05 +0800</pubDate>
      
      <guid>http://danigong.github.io/post/python_property/</guid>
      <description>

&lt;h2 id=&#34;python-属性-property-详解:05e96a11594e29fc27254b4ee09656d0&#34;&gt;Python“属性（property）”详解&lt;/h2&gt;

&lt;p&gt;Python中有一个被称为属性函数(property)的小概念，它可以做一些有用的事情。在这篇文章中，我们将看到如何能做以下几点：&lt;/p&gt;

&lt;h3 id=&#34;将类方法转换为只读属性:05e96a11594e29fc27254b4ee09656d0&#34;&gt;将类方法转换为只读属性&lt;/h3&gt;

&lt;h3 id=&#34;重新实现一个属性的setter和getter方法:05e96a11594e29fc27254b4ee09656d0&#34;&gt;重新实现一个属性的setter和getter方法&lt;/h3&gt;

&lt;p&gt;在本文中，您将学习如何以几种不同的方式来使用内置的属性函数。希望读到文章的末尾时，你能看到它是多么有用。&lt;/p&gt;

&lt;p&gt;开始&lt;/p&gt;

&lt;p&gt;使用属性函数的最简单的方法之一是将它作为一个方法的装饰器来使用。这可以让你将一个类方法转变成一个类属性。当我需要做某些值的合并时，我发现这很有用。其他想要获取它作为方法使用的人，发现在写转换函数时它很有用。让我们来看一个简单的例子：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Person(object):
    &amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;
 
    #----------------------------------------------------------------------
    def __init__(self, first_name, last_name):
        &amp;quot;&amp;quot;&amp;quot;Constructor&amp;quot;&amp;quot;&amp;quot;
        self.first_name = first_name
        self.last_name = last_name
 
    #----------------------------------------------------------------------
    @property
    def full_name(self):
        &amp;quot;&amp;quot;&amp;quot;
        Return the full name
        &amp;quot;&amp;quot;&amp;quot;
        return &amp;quot;%s %s&amp;quot; % (self.first_name, self.last_name)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在上面的代码中，我们创建了两个类属性：self.first_name和self.last_name。接下来，我们创建了一个full_name方法，它有一个@property装饰器。这使我们能够在Python解释器会话中有如下的交互：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; person = Person(&amp;quot;Mike&amp;quot;, &amp;quot;Driscoll&amp;quot;)
&amp;gt;&amp;gt;&amp;gt; person.full_name
&#39;Mike Driscoll&#39;
&amp;gt;&amp;gt;&amp;gt; person.first_name
&#39;Mike&#39;
&amp;gt;&amp;gt;&amp;gt; person.full_name = &amp;quot;Jackalope&amp;quot;
Traceback (most recent call last):
  File &amp;quot;&amp;lt;string&amp;gt;&amp;quot;, line 1, in &amp;lt;fragment&amp;gt;
AttributeError: can&#39;t set attribute
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;正如你所看到的，因为我们将方法变成了属性，我们可以使用正常的点符号访问它。但是，如果我们试图将该属性设为其他值，我们会引发一个AttributeError错误。改变full_name属性的唯一方法是间接这样做：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; person.first_name = &amp;quot;Dan&amp;quot;
&amp;gt;&amp;gt;&amp;gt; person.full_name
&#39;Dan Driscoll&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这是一种限制，因此让我们来看看另一个例子，其中我们可以创建一个允许设置的属性。&lt;/p&gt;

&lt;p&gt;使用Python property取代setter和getter方法&lt;/p&gt;

&lt;p&gt;让我们假设我们有一些遗留代码，它们是由一些对Python理解得不够好的人写的。如果你像我一样，你之前已经看到过这类的代码：&lt;/p&gt;

&lt;p&gt;Python&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Fees(object):
    &amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;
 
    #----------------------------------------------------------------------
    def __init__(self):
        &amp;quot;&amp;quot;&amp;quot;Constructor&amp;quot;&amp;quot;&amp;quot;
        self._fee = None
 
    #----------------------------------------------------------------------
    def get_fee(self):
        &amp;quot;&amp;quot;&amp;quot;
        Return the current fee
        &amp;quot;&amp;quot;&amp;quot;
        return self._fee
 
    #----------------------------------------------------------------------
    def set_fee(self, value):
        &amp;quot;&amp;quot;&amp;quot;
        Set the fee
        &amp;quot;&amp;quot;&amp;quot;
        if isinstance(value, str):
            self._fee = Decimal(value)
        elif isinstance(value, Decimal):
            self._fee = value
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;要使用这个类，我们必须要使用定义的getter和setter方法​​：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; f = Fees()
&amp;gt;&amp;gt;&amp;gt; f.set_fee(&amp;quot;1&amp;quot;)
&amp;gt;&amp;gt;&amp;gt; f.get_fee()
Decimal(&#39;1&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果你想添加可以使用正常点符号访问的属性，而不破坏所有依赖于这段代码的应用程序，你可以通过添加一个属性函数非常简单地改变它：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Fees(object):
    &amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;
 
    #----------------------------------------------------------------------
    def __init__(self):
        &amp;quot;&amp;quot;&amp;quot;Constructor&amp;quot;&amp;quot;&amp;quot;
        self._fee = None
 
    #----------------------------------------------------------------------
    def get_fee(self):
        &amp;quot;&amp;quot;&amp;quot;
        Return the current fee
        &amp;quot;&amp;quot;&amp;quot;
        return self._fee
 
    #----------------------------------------------------------------------
    def set_fee(self, value):
        &amp;quot;&amp;quot;&amp;quot;
        Set the fee
        &amp;quot;&amp;quot;&amp;quot;
        if isinstance(value, str):
            self._fee = Decimal(value)
        elif isinstance(value, Decimal):
            self._fee = value
 
    fee = property(get_fee, set_fee)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们在这段代码的末尾添加了一行。现在我们可以这样做：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; f = Fees()
&amp;gt;&amp;gt;&amp;gt; f.set_fee(&amp;quot;1&amp;quot;)
&amp;gt;&amp;gt;&amp;gt; f.fee
Decimal(&#39;1&#39;)
&amp;gt;&amp;gt;&amp;gt; f.fee = &amp;quot;2&amp;quot;
&amp;gt;&amp;gt;&amp;gt; f.get_fee()
Decimal(&#39;2&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;正如你所看到的，当我们以这种方式使用属性函数时，它允许fee属性设置并获取值本身而不破坏原有代码。让我们使用属性装饰器来重写这段代码，看看我们是否能得到一个允许设置的属性值。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Fees(object):
    &amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;
 
    #----------------------------------------------------------------------
    def __init__(self):
        &amp;quot;&amp;quot;&amp;quot;Constructor&amp;quot;&amp;quot;&amp;quot;
        self._fee = None
 
    #----------------------------------------------------------------------
    @property
    def fee(self):
        &amp;quot;&amp;quot;&amp;quot;
        The fee property - the getter
        &amp;quot;&amp;quot;&amp;quot;
        return self._fee
 
    #----------------------------------------------------------------------
    @fee.setter
    def fee(self, value):
        &amp;quot;&amp;quot;&amp;quot;
        The setter of the fee property
        &amp;quot;&amp;quot;&amp;quot;
        if isinstance(value, str):
            self._fee = Decimal(value)
        elif isinstance(value, Decimal):
            self._fee = value
 
#----------------------------------------------------------------------
if __name__ == &amp;quot;__main__&amp;quot;:
    f = Fees()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的代码演示了如何为fee属性创建一个setter方法。你可以用一个名为@fee.setter的装饰器装饰第二个方法名也为fee的方法来实现这个。当你如下所做时，setter被调用：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; f = Fees()
&amp;gt;&amp;gt;&amp;gt; f.fee = &amp;quot;1&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果你看属性函数的说明，它有fget, fset, fdel和doc几个参数。如果你想对属性使用del命令，你可以使用@fee.deleter创建另一个装饰器来装饰相同名字的函数从而实现删除的同样效果。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>